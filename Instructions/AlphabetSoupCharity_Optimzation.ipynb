{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>996009318</td>\n",
       "      <td>THE LIONS CLUB OF HONOLULU KAMEHAMEHA</td>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>996010315</td>\n",
       "      <td>INTERNATIONAL ASSOCIATION OF LIONS CLUBS</td>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>996012607</td>\n",
       "      <td>PTA HAWAII CONGRESS</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>996015768</td>\n",
       "      <td>AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...</td>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>996086871</td>\n",
       "      <td>WATERHOUSE CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             EIN                                               NAME  \\\n",
       "0       10520599                       BLUE KNIGHTS MOTORCYCLE CLUB   \n",
       "1       10531628             AMERICAN CHESAPEAKE CLUB CHARITABLE TR   \n",
       "2       10547893                 ST CLOUD PROFESSIONAL FIREFIGHTERS   \n",
       "3       10553066                     SOUTHSIDE ATHLETIC ASSOCIATION   \n",
       "4       10556103           GENETIC RESEARCH INSTITUTE OF THE DESERT   \n",
       "...          ...                                                ...   \n",
       "34294  996009318              THE LIONS CLUB OF HONOLULU KAMEHAMEHA   \n",
       "34295  996010315           INTERNATIONAL ASSOCIATION OF LIONS CLUBS   \n",
       "34296  996012607                                PTA HAWAII CONGRESS   \n",
       "34297  996015768  AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...   \n",
       "34298  996086871                           WATERHOUSE CHARITABLE TR   \n",
       "\n",
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0                  T10       Independent          C1000    ProductDev   \n",
       "1                   T3       Independent          C2000  Preservation   \n",
       "2                   T5  CompanySponsored          C3000    ProductDev   \n",
       "3                   T3  CompanySponsored          C2000  Preservation   \n",
       "4                   T3       Independent          C1000     Heathcare   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
       "0       Association       1              0                      N      5000   \n",
       "1      Co-operative       1         1-9999                      N    108590   \n",
       "2       Association       1              0                      N      5000   \n",
       "3             Trust       1    10000-24999                      N      6692   \n",
       "4             Trust       1  100000-499999                      N    142590   \n",
       "...             ...     ...            ...                    ...       ...   \n",
       "34294   Association       1              0                      N      5000   \n",
       "34295   Association       1              0                      N      5000   \n",
       "34296   Association       1              0                      N      5000   \n",
       "34297   Association       1              0                      N      5000   \n",
       "34298  Co-operative       1          1M-5M                      N  36500179   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "34294              0  \n",
       "34295              0  \n",
       "34296              0  \n",
       "34297              1  \n",
       "34298              0  \n",
       "\n",
       "[34299 rows x 12 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import your dependencies and read in the `charity_data.csv` to a Pandas DataFrame.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"../Resources/charity_data.csv\")\n",
    "application_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    34272\n",
       "Y       27\n",
       "Name: SPECIAL_CONSIDERATIONS, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df['SPECIAL_CONSIDERATIONS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>31452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10M-50M</td>\n",
       "      <td>7508025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T7</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>94389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "5               T3       Independent          C1200  Preservation   \n",
       "6               T3       Independent          C1000  Preservation   \n",
       "7               T3       Independent          C2000  Preservation   \n",
       "8               T7       Independent          C1000    ProductDev   \n",
       "9               T5  CompanySponsored          C3000    ProductDev   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT  ASK_AMT  IS_SUCCESSFUL  \n",
       "0   Association       1              0     5000              1  \n",
       "1  Co-operative       1         1-9999   108590              1  \n",
       "2   Association       1              0     5000              0  \n",
       "3         Trust       1    10000-24999     6692              1  \n",
       "4         Trust       1  100000-499999   142590              1  \n",
       "5         Trust       1              0     5000              1  \n",
       "6         Trust       1  100000-499999    31452              1  \n",
       "7         Trust       1        10M-50M  7508025              1  \n",
       "8         Trust       1         1-9999    94389              1  \n",
       "9   Association       1              0     5000              0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocess the dataset like you did in Step 1, Be sure to adjust for any modifications that came out of optimizing the model.\n",
    "\n",
    "application_df = application_df.drop([\"EIN\", \"NAME\", \"SPECIAL_CONSIDERATIONS\"], axis = 1)\n",
    "application_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "Other      804\n",
       "T8         737\n",
       "T7         725\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_types_to_replace = [\"T9\",\"T13\",\"T12\",\"T2\",\"T14\",\"T25\",\"T15\",\"T29\",\"T17\",\"T10\"]\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "         ...  \n",
       "C2600        1\n",
       "C2150        1\n",
       "C2380        1\n",
       "C2190        1\n",
       "C1732        1\n",
       "Name: CLASSIFICATION, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_count = application_df[\"CLASSIFICATION\"].value_counts()\n",
    "value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Other      887\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_to_replace = value_count[value_count < 115].index\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in small_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "\n",
    "application_df[\"CLASSIFICATION\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8597806340"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_amt = application_df['ASK_AMT']\n",
    "\n",
    "for amt in ask_amt:\n",
    "    amt = int(amt)\n",
    "\n",
    "ask_amt.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>ASK_AMT_CAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>100k-500k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>100k-500k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>31452</td>\n",
       "      <td>1</td>\n",
       "      <td>25k-100k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10M-50M</td>\n",
       "      <td>7508025</td>\n",
       "      <td>1</td>\n",
       "      <td>5m-10m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T7</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>94389</td>\n",
       "      <td>1</td>\n",
       "      <td>25k-100k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>25000-99999</td>\n",
       "      <td>69656</td>\n",
       "      <td>0</td>\n",
       "      <td>25k-100k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>165593</td>\n",
       "      <td>0</td>\n",
       "      <td>100k-500k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Other</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>25000-99999</td>\n",
       "      <td>5301</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>50M+</td>\n",
       "      <td>86380556</td>\n",
       "      <td>0</td>\n",
       "      <td>50m+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>376109</td>\n",
       "      <td>0</td>\n",
       "      <td>100k-500k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0             Other       Independent          C1000    ProductDev   \n",
       "1                T3       Independent          C2000  Preservation   \n",
       "2                T5  CompanySponsored          C3000    ProductDev   \n",
       "3                T3  CompanySponsored          C2000  Preservation   \n",
       "4                T3       Independent          C1000     Heathcare   \n",
       "5                T3       Independent          C1200  Preservation   \n",
       "6                T3       Independent          C1000  Preservation   \n",
       "7                T3       Independent          C2000  Preservation   \n",
       "8                T7       Independent          C1000    ProductDev   \n",
       "9                T5  CompanySponsored          C3000    ProductDev   \n",
       "10               T3       Independent          C1200  Preservation   \n",
       "11               T3       Independent          C2000  Preservation   \n",
       "12               T3  CompanySponsored          C1200  Preservation   \n",
       "13               T3       Independent          Other  Preservation   \n",
       "14               T3       Independent          C1000  Preservation   \n",
       "15               T3       Independent          C1200  Preservation   \n",
       "16               T3       Independent          C2000  Preservation   \n",
       "17               T3       Independent          C1000     Heathcare   \n",
       "18               T3  CompanySponsored          C1000  Preservation   \n",
       "19               T3  CompanySponsored          C1000  Preservation   \n",
       "\n",
       "    ORGANIZATION  STATUS     INCOME_AMT   ASK_AMT  IS_SUCCESSFUL ASK_AMT_CAT  \n",
       "0    Association       1              0      5000              1      <10000  \n",
       "1   Co-operative       1         1-9999    108590              1   100k-500k  \n",
       "2    Association       1              0      5000              0      <10000  \n",
       "3          Trust       1    10000-24999      6692              1      <10000  \n",
       "4          Trust       1  100000-499999    142590              1   100k-500k  \n",
       "5          Trust       1              0      5000              1      <10000  \n",
       "6          Trust       1  100000-499999     31452              1    25k-100k  \n",
       "7          Trust       1        10M-50M   7508025              1      5m-10m  \n",
       "8          Trust       1         1-9999     94389              1    25k-100k  \n",
       "9    Association       1              0      5000              0      <10000  \n",
       "10         Trust       1    25000-99999     69656              0    25k-100k  \n",
       "11         Trust       1  100000-499999    165593              0   100k-500k  \n",
       "12   Association       1              0      5000              1      <10000  \n",
       "13         Trust       1    25000-99999      5301              1      <10000  \n",
       "14         Trust       1              0      5000              1      <10000  \n",
       "15         Trust       1              0      5000              1      <10000  \n",
       "16         Trust       1              0      5000              1      <10000  \n",
       "17         Trust       1           50M+  86380556              0        50m+  \n",
       "18         Trust       1              0      5000              0      <10000  \n",
       "19         Trust       1  100000-499999    376109              0   100k-500k  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0,10000,25000,100000,500000,1000000,5000000,10000000,50000000,9000000000]\n",
    "\n",
    "bin_labels = [\"<10000\",\"10k-25k\",\"25k-100k\",\"100k-500k\",\"500k-1m\",\"1m-5m\",\"5m-10m\",\"10m-50m\",\"50m+\",]\n",
    "\n",
    "application_df['ASK_AMT_CAT'] = pd.cut(ask_amt, bins, labels=bin_labels)\n",
    "\n",
    "application_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Independent         18480\n",
       "CompanySponsored    15705\n",
       "Other                 114\n",
       "Name: AFFILIATION, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affiliation_types_to_replace = [\"Family/Parent\",\"National\",\"Regional\"]\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in affiliation_types_to_replace:\n",
    "    application_df['AFFILIATION'] = application_df['AFFILIATION'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['AFFILIATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trust          23515\n",
       "Association    10255\n",
       "Other            529\n",
       "Name: ORGANIZATION, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organisation_types_to_replace = [\"Co-operative\",\"Corporation\"]\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in affiliation_types_to_replace:\n",
    "    application_df['ORGANIZATION'] = application_df['ORGANIZATION'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['ORGANIZATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>ASK_AMT_CAT_&lt;10000</th>\n",
       "      <th>ASK_AMT_CAT_10k-25k</th>\n",
       "      <th>ASK_AMT_CAT_25k-100k</th>\n",
       "      <th>ASK_AMT_CAT_100k-500k</th>\n",
       "      <th>ASK_AMT_CAT_500k-1m</th>\n",
       "      <th>ASK_AMT_CAT_1m-5m</th>\n",
       "      <th>ASK_AMT_CAT_5m-10m</th>\n",
       "      <th>ASK_AMT_CAT_10m-50m</th>\n",
       "      <th>ASK_AMT_CAT_50m+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>1</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0           1      5000              1                       1   \n",
       "1           1    108590              1                       0   \n",
       "2           1      5000              0                       0   \n",
       "3           1      6692              1                       0   \n",
       "4           1    142590              1                       0   \n",
       "...       ...       ...            ...                     ...   \n",
       "34294       1      5000              0                       0   \n",
       "34295       1      5000              0                       0   \n",
       "34296       1      5000              0                       0   \n",
       "34297       1      5000              1                       0   \n",
       "34298       1  36500179              0                       0   \n",
       "\n",
       "       APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                         0                    0                    0   \n",
       "1                         0                    1                    0   \n",
       "2                         0                    0                    0   \n",
       "3                         0                    1                    0   \n",
       "4                         0                    1                    0   \n",
       "...                     ...                  ...                  ...   \n",
       "34294                     0                    0                    1   \n",
       "34295                     0                    0                    1   \n",
       "34296                     0                    1                    0   \n",
       "34297                     0                    0                    0   \n",
       "34298                     0                    1                    0   \n",
       "\n",
       "       APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n",
       "0                        0                    0                    0  ...   \n",
       "1                        0                    0                    0  ...   \n",
       "2                        1                    0                    0  ...   \n",
       "3                        0                    0                    0  ...   \n",
       "4                        0                    0                    0  ...   \n",
       "...                    ...                  ...                  ...  ...   \n",
       "34294                    0                    0                    0  ...   \n",
       "34295                    0                    0                    0  ...   \n",
       "34296                    0                    0                    0  ...   \n",
       "34297                    1                    0                    0  ...   \n",
       "34298                    0                    0                    0  ...   \n",
       "\n",
       "       INCOME_AMT_5M-10M  ASK_AMT_CAT_<10000  ASK_AMT_CAT_10k-25k  \\\n",
       "0                      0                   1                    0   \n",
       "1                      0                   0                    0   \n",
       "2                      0                   1                    0   \n",
       "3                      0                   1                    0   \n",
       "4                      0                   0                    0   \n",
       "...                  ...                 ...                  ...   \n",
       "34294                  0                   1                    0   \n",
       "34295                  0                   1                    0   \n",
       "34296                  0                   1                    0   \n",
       "34297                  0                   1                    0   \n",
       "34298                  0                   0                    0   \n",
       "\n",
       "       ASK_AMT_CAT_25k-100k  ASK_AMT_CAT_100k-500k  ASK_AMT_CAT_500k-1m  \\\n",
       "0                         0                      0                    0   \n",
       "1                         0                      1                    0   \n",
       "2                         0                      0                    0   \n",
       "3                         0                      0                    0   \n",
       "4                         0                      1                    0   \n",
       "...                     ...                    ...                  ...   \n",
       "34294                     0                      0                    0   \n",
       "34295                     0                      0                    0   \n",
       "34296                     0                      0                    0   \n",
       "34297                     0                      0                    0   \n",
       "34298                     0                      0                    0   \n",
       "\n",
       "       ASK_AMT_CAT_1m-5m  ASK_AMT_CAT_5m-10m  ASK_AMT_CAT_10m-50m  \\\n",
       "0                      0                   0                    0   \n",
       "1                      0                   0                    0   \n",
       "2                      0                   0                    0   \n",
       "3                      0                   0                    0   \n",
       "4                      0                   0                    0   \n",
       "...                  ...                 ...                  ...   \n",
       "34294                  0                   0                    0   \n",
       "34295                  0                   0                    0   \n",
       "34296                  0                   0                    0   \n",
       "34297                  0                   0                    0   \n",
       "34298                  0                   0                    1   \n",
       "\n",
       "       ASK_AMT_CAT_50m+  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "34294                 0  \n",
       "34295                 0  \n",
       "34296                 0  \n",
       "34297                 0  \n",
       "34298                 0  \n",
       "\n",
       "[34299 rows x 50 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorized = pd.get_dummies(application_df, columns = ['APPLICATION_TYPE','CLASSIFICATION','AFFILIATION', 'USE_CASE', 'ORGANIZATION','INCOME_AMT','ASK_AMT_CAT'])\n",
    "categorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Model Accuracy = 0.7267"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Revision 1 - Dataset change to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Design a neural network model, and be sure to adjust for modifications that will optimize the model to achieve higher than 75% accuracy.\n",
    "\n",
    "# Split our preprocessed data into our features and target arrays\n",
    "X=categorized.drop(['IS_SUCCESSFUL'], axis = 1).values\n",
    "y= categorized['IS_SUCCESSFUL']\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_43 (Dense)            (None, 4)                 200       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225\n",
      "Trainable params: 225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn1 = tf.keras.models.Sequential()\n",
    "\n",
    "input_features = len(X_train_scaled[0])\n",
    "\n",
    "# Add our first Dense layer, including the input layer\n",
    "nn1.add(tf.keras.layers.Dense(units=4, activation=\"relu\", input_dim=input_features))\n",
    "\n",
    "nn1.add(tf.keras.layers.Dense(units=4, activation='relu'))\n",
    "\n",
    "# Add the output layer that uses a probability activation function\n",
    "nn1.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Check the structure of the Sequential model\n",
    "nn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "print(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn1.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.6546 - accuracy: 0.6109\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.6037 - accuracy: 0.7056\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5876 - accuracy: 0.7097\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5820 - accuracy: 0.7119\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5750 - accuracy: 0.7207\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5709 - accuracy: 0.7235\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5691 - accuracy: 0.7228\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5677 - accuracy: 0.7226\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5657 - accuracy: 0.7236\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5651 - accuracy: 0.7255\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5646 - accuracy: 0.7254\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5642 - accuracy: 0.7247\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5637 - accuracy: 0.7262\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5635 - accuracy: 0.7250\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5630 - accuracy: 0.7266\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5626 - accuracy: 0.7277\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5622 - accuracy: 0.7261\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5620 - accuracy: 0.7283\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5616 - accuracy: 0.7282\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5615 - accuracy: 0.7284\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5607 - accuracy: 0.7289\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5609 - accuracy: 0.7285\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5608 - accuracy: 0.7280\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5607 - accuracy: 0.7287\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5606 - accuracy: 0.7292\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5604 - accuracy: 0.7289\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5604 - accuracy: 0.7293\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5603 - accuracy: 0.7284\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5603 - accuracy: 0.7289\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5602 - accuracy: 0.7289\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5600 - accuracy: 0.7285\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5600 - accuracy: 0.7291\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5601 - accuracy: 0.7287\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5598 - accuracy: 0.7294\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5599 - accuracy: 0.7291\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5599 - accuracy: 0.7306\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5599 - accuracy: 0.7298\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5598 - accuracy: 0.7283\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5597 - accuracy: 0.7292\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5598 - accuracy: 0.7293\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5597 - accuracy: 0.7289\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5598 - accuracy: 0.7283\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5597 - accuracy: 0.7292\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5596 - accuracy: 0.7296\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5593 - accuracy: 0.7309\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5591 - accuracy: 0.7307\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5590 - accuracy: 0.7319\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5590 - accuracy: 0.7311\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5589 - accuracy: 0.7315\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5590 - accuracy: 0.7312\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5588 - accuracy: 0.7308\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5587 - accuracy: 0.7308\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5586 - accuracy: 0.7307\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5589 - accuracy: 0.7309\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5587 - accuracy: 0.7312\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5588 - accuracy: 0.7312\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5587 - accuracy: 0.7307\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5586 - accuracy: 0.7311\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5583 - accuracy: 0.7308\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5586 - accuracy: 0.7311\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5586 - accuracy: 0.7306\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5585 - accuracy: 0.7314\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5586 - accuracy: 0.7315\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5585 - accuracy: 0.7306\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5584 - accuracy: 0.7310\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5585 - accuracy: 0.7312\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5583 - accuracy: 0.7311\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5584 - accuracy: 0.7317\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5582 - accuracy: 0.7315\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5582 - accuracy: 0.7315\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5584 - accuracy: 0.7315\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5583 - accuracy: 0.7308\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5583 - accuracy: 0.7314\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5583 - accuracy: 0.7313\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5582 - accuracy: 0.7317\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5582 - accuracy: 0.7316\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5582 - accuracy: 0.7305\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5580 - accuracy: 0.7325\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5582 - accuracy: 0.7311\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5582 - accuracy: 0.7320\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5581 - accuracy: 0.7309\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5581 - accuracy: 0.7308\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5581 - accuracy: 0.7313\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5580 - accuracy: 0.7308\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5578 - accuracy: 0.7313\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5580 - accuracy: 0.7311\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5579 - accuracy: 0.7314\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5582 - accuracy: 0.7316\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5579 - accuracy: 0.7318\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5580 - accuracy: 0.7317\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5579 - accuracy: 0.7311\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5579 - accuracy: 0.7315\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5578 - accuracy: 0.7311\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5580 - accuracy: 0.7311\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5577 - accuracy: 0.7317\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5581 - accuracy: 0.7318\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5578 - accuracy: 0.7316\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5579 - accuracy: 0.7308\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5579 - accuracy: 0.7311\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5577 - accuracy: 0.7316\n"
     ]
    }
   ],
   "source": [
    "fit_nn1 = nn1.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5641 - accuracy: 0.7249 - 424ms/epoch - 2ms/step\n",
      "Loss: 0.5640548467636108, Accuracy: 0.7248979806900024\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn1.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14034207908>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_nn1.history)\n",
    "\n",
    "# Increase the index by 1 to match the number of epochs\n",
    "history_df.index += 1\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revised model accuracy is 0.7248, original at 0.7267"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Revision 2 - Add Layer and increase Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 4)                 200       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 245\n",
      "Trainable params: 245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn2 = tf.keras.models.Sequential()\n",
    "\n",
    "input_features = len(X_train_scaled[0])\n",
    "\n",
    "# Add our first Dense layer, including the input layer\n",
    "nn2.add(tf.keras.layers.Dense(units=4, activation=\"relu\", input_dim=input_features))\n",
    "\n",
    "nn2.add(tf.keras.layers.Dense(units=4, activation='relu'))\n",
    "\n",
    "nn2.add(tf.keras.layers.Dense(units=4, activation='relu'))\n",
    "\n",
    "# Add the output layer that uses a probability activation function\n",
    "nn2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Check the structure of the Sequential model\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn2.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.6335 - accuracy: 0.6620\n",
      "Epoch 2/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5761 - accuracy: 0.7250\n",
      "Epoch 3/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5675 - accuracy: 0.7279\n",
      "Epoch 4/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5644 - accuracy: 0.7279\n",
      "Epoch 5/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5625 - accuracy: 0.7293\n",
      "Epoch 6/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5596 - accuracy: 0.7295\n",
      "Epoch 7/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5552 - accuracy: 0.7292\n",
      "Epoch 8/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5531 - accuracy: 0.7301\n",
      "Epoch 9/200\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5519 - accuracy: 0.7293\n",
      "Epoch 10/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5513 - accuracy: 0.7308\n",
      "Epoch 11/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5505 - accuracy: 0.7299\n",
      "Epoch 12/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5499 - accuracy: 0.7311\n",
      "Epoch 13/200\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5495 - accuracy: 0.7304\n",
      "Epoch 14/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5493 - accuracy: 0.7294\n",
      "Epoch 15/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5488 - accuracy: 0.7301\n",
      "Epoch 16/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5486 - accuracy: 0.7307\n",
      "Epoch 17/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5484 - accuracy: 0.7310\n",
      "Epoch 18/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5484 - accuracy: 0.7306\n",
      "Epoch 19/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5483 - accuracy: 0.7311\n",
      "Epoch 20/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5481 - accuracy: 0.7315\n",
      "Epoch 21/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5481 - accuracy: 0.7310\n",
      "Epoch 22/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5480 - accuracy: 0.7311\n",
      "Epoch 23/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5479 - accuracy: 0.7319\n",
      "Epoch 24/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7322\n",
      "Epoch 25/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5476 - accuracy: 0.7325\n",
      "Epoch 26/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5477 - accuracy: 0.7319\n",
      "Epoch 27/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5473 - accuracy: 0.7321\n",
      "Epoch 28/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5469 - accuracy: 0.7324\n",
      "Epoch 29/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5471 - accuracy: 0.7321\n",
      "Epoch 30/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5467 - accuracy: 0.7318\n",
      "Epoch 31/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7325\n",
      "Epoch 32/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7322\n",
      "Epoch 33/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7329\n",
      "Epoch 34/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5463 - accuracy: 0.7323\n",
      "Epoch 35/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5464 - accuracy: 0.7326\n",
      "Epoch 36/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7325\n",
      "Epoch 37/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7328\n",
      "Epoch 38/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7336\n",
      "Epoch 39/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5461 - accuracy: 0.7334\n",
      "Epoch 40/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7332\n",
      "Epoch 41/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7332\n",
      "Epoch 42/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7332\n",
      "Epoch 43/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7338\n",
      "Epoch 44/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7331\n",
      "Epoch 45/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5460 - accuracy: 0.7325\n",
      "Epoch 46/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7329\n",
      "Epoch 47/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7322\n",
      "Epoch 48/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.7332\n",
      "Epoch 49/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7324\n",
      "Epoch 50/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5457 - accuracy: 0.7331\n",
      "Epoch 51/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7335\n",
      "Epoch 52/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7325\n",
      "Epoch 53/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7323\n",
      "Epoch 54/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7330\n",
      "Epoch 55/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7333\n",
      "Epoch 56/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7336\n",
      "Epoch 57/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7329\n",
      "Epoch 58/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.7334\n",
      "Epoch 59/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.7321\n",
      "Epoch 60/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7324\n",
      "Epoch 61/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5454 - accuracy: 0.7325\n",
      "Epoch 62/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7325\n",
      "Epoch 63/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5455 - accuracy: 0.7328\n",
      "Epoch 64/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5455 - accuracy: 0.7326\n",
      "Epoch 65/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5455 - accuracy: 0.7322\n",
      "Epoch 66/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7322\n",
      "Epoch 67/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5455 - accuracy: 0.7325\n",
      "Epoch 68/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7327\n",
      "Epoch 69/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7321\n",
      "Epoch 70/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5454 - accuracy: 0.7322\n",
      "Epoch 71/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7332\n",
      "Epoch 72/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5455 - accuracy: 0.7316\n",
      "Epoch 73/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5455 - accuracy: 0.7330\n",
      "Epoch 74/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7329\n",
      "Epoch 75/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7320\n",
      "Epoch 76/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7331\n",
      "Epoch 77/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7320\n",
      "Epoch 78/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7331\n",
      "Epoch 79/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7323\n",
      "Epoch 80/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7332\n",
      "Epoch 81/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7323\n",
      "Epoch 82/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7335\n",
      "Epoch 83/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7333\n",
      "Epoch 84/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7337\n",
      "Epoch 85/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7341\n",
      "Epoch 86/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7333\n",
      "Epoch 87/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7329\n",
      "Epoch 88/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7334\n",
      "Epoch 89/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7336\n",
      "Epoch 90/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7338\n",
      "Epoch 91/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7333\n",
      "Epoch 92/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7329\n",
      "Epoch 93/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7331\n",
      "Epoch 94/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7330\n",
      "Epoch 95/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7328\n",
      "Epoch 96/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7325\n",
      "Epoch 97/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7338\n",
      "Epoch 98/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7337\n",
      "Epoch 99/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7340\n",
      "Epoch 100/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7329\n",
      "Epoch 101/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7333\n",
      "Epoch 102/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7338\n",
      "Epoch 103/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7329\n",
      "Epoch 104/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7331\n",
      "Epoch 105/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7332\n",
      "Epoch 106/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7334\n",
      "Epoch 107/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7336\n",
      "Epoch 108/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7327\n",
      "Epoch 109/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7332\n",
      "Epoch 110/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7337\n",
      "Epoch 111/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7334\n",
      "Epoch 112/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.7339\n",
      "Epoch 113/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7338\n",
      "Epoch 114/200\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7335\n",
      "Epoch 115/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7330\n",
      "Epoch 116/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7327\n",
      "Epoch 117/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7337\n",
      "Epoch 118/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7334\n",
      "Epoch 119/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7326\n",
      "Epoch 120/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7340\n",
      "Epoch 121/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7339\n",
      "Epoch 122/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7330\n",
      "Epoch 123/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7335\n",
      "Epoch 124/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7327\n",
      "Epoch 125/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7341\n",
      "Epoch 126/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7333\n",
      "Epoch 127/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7338\n",
      "Epoch 128/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7333\n",
      "Epoch 129/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7334\n",
      "Epoch 130/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7338\n",
      "Epoch 131/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7336\n",
      "Epoch 132/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7331\n",
      "Epoch 133/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7328\n",
      "Epoch 134/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7334\n",
      "Epoch 135/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7335\n",
      "Epoch 136/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7334\n",
      "Epoch 137/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7330\n",
      "Epoch 138/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7330\n",
      "Epoch 139/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7329\n",
      "Epoch 140/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7334\n",
      "Epoch 141/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7335\n",
      "Epoch 142/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7329\n",
      "Epoch 143/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7338\n",
      "Epoch 144/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7335\n",
      "Epoch 145/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7335\n",
      "Epoch 146/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7331\n",
      "Epoch 147/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7332\n",
      "Epoch 148/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7335\n",
      "Epoch 149/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7339\n",
      "Epoch 150/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7336\n",
      "Epoch 151/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7339\n",
      "Epoch 152/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7341\n",
      "Epoch 153/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7338\n",
      "Epoch 154/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7336\n",
      "Epoch 155/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7341\n",
      "Epoch 156/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7336\n",
      "Epoch 157/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7339\n",
      "Epoch 158/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7335\n",
      "Epoch 159/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7332\n",
      "Epoch 160/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7336\n",
      "Epoch 161/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7335\n",
      "Epoch 162/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7338\n",
      "Epoch 163/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7339\n",
      "Epoch 164/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7334\n",
      "Epoch 165/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7334\n",
      "Epoch 166/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7341\n",
      "Epoch 167/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7336\n",
      "Epoch 168/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7343\n",
      "Epoch 169/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7331\n",
      "Epoch 170/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7339\n",
      "Epoch 171/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7336\n",
      "Epoch 172/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7341\n",
      "Epoch 173/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7339\n",
      "Epoch 174/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7341\n",
      "Epoch 175/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7339\n",
      "Epoch 176/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7333\n",
      "Epoch 177/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7336\n",
      "Epoch 178/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7337\n",
      "Epoch 179/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7342\n",
      "Epoch 180/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7332\n",
      "Epoch 181/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7334\n",
      "Epoch 182/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7334\n",
      "Epoch 183/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7337\n",
      "Epoch 184/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7342\n",
      "Epoch 185/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7335\n",
      "Epoch 186/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7336\n",
      "Epoch 187/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7334\n",
      "Epoch 188/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7338\n",
      "Epoch 189/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7333\n",
      "Epoch 190/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7335\n",
      "Epoch 191/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7336\n",
      "Epoch 192/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7337\n",
      "Epoch 193/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.7339\n",
      "Epoch 194/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7336\n",
      "Epoch 195/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.7341\n",
      "Epoch 196/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7336\n",
      "Epoch 197/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7339\n",
      "Epoch 198/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7338\n",
      "Epoch 199/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.7339\n",
      "Epoch 200/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7338\n"
     ]
    }
   ],
   "source": [
    "fit_nn2 = nn2.fit(X_train_scaled, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5507 - accuracy: 0.7311 - 296ms/epoch - 1ms/step\n",
      "Loss: 0.5506758093833923, Accuracy: 0.7310787439346313\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn2.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1402c434f48>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df2 = pd.DataFrame(fit_nn2.history)\n",
    "\n",
    "# Increase the index by 1 to match the number of epochs\n",
    "history_df2.index += 1\n",
    "\n",
    "# Plot the loss\n",
    "history_df2.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model revision 2 accuract = 0.7310"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Revision 3 - change to compile step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 4)                 200       \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 245\n",
      "Trainable params: 245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn3 = tf.keras.models.Sequential()\n",
    "\n",
    "input_features = len(X_train_scaled[0])\n",
    "\n",
    "# Add our first Dense layer, including the input layer\n",
    "nn3.add(tf.keras.layers.Dense(units=4, activation=\"relu\", input_dim=input_features))\n",
    "\n",
    "nn3.add(tf.keras.layers.Dense(units=4, activation='relu'))\n",
    "\n",
    "nn3.add(tf.keras.layers.Dense(units=4, activation='relu'))\n",
    "\n",
    "# Add the output layer that uses a probability activation function\n",
    "nn3.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Check the structure of the Sequential model\n",
    "nn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn3.compile(loss=\"binary_crossentropy\", optimizer='Nadam', metrics=[\"accuracy\"], steps_per_execution = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.6460 - accuracy: 0.6297\n",
      "Epoch 2/200\n",
      "804/804 [==============================] - 0s 528us/step - loss: 0.5692 - accuracy: 0.7217\n",
      "Epoch 3/200\n",
      "804/804 [==============================] - 0s 523us/step - loss: 0.5603 - accuracy: 0.7247\n",
      "Epoch 4/200\n",
      "804/804 [==============================] - 0s 459us/step - loss: 0.5566 - accuracy: 0.7266\n",
      "Epoch 5/200\n",
      "804/804 [==============================] - 0s 476us/step - loss: 0.5545 - accuracy: 0.7268\n",
      "Epoch 6/200\n",
      "804/804 [==============================] - 0s 474us/step - loss: 0.5534 - accuracy: 0.7287\n",
      "Epoch 7/200\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5528 - accuracy: 0.7289\n",
      "Epoch 8/200\n",
      "804/804 [==============================] - 0s 432us/step - loss: 0.5523 - accuracy: 0.7292\n",
      "Epoch 9/200\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5516 - accuracy: 0.7291\n",
      "Epoch 10/200\n",
      "804/804 [==============================] - 0s 458us/step - loss: 0.5514 - accuracy: 0.7294\n",
      "Epoch 11/200\n",
      "804/804 [==============================] - 0s 538us/step - loss: 0.5511 - accuracy: 0.7293\n",
      "Epoch 12/200\n",
      "804/804 [==============================] - 0s 569us/step - loss: 0.5506 - accuracy: 0.7298\n",
      "Epoch 13/200\n",
      "804/804 [==============================] - 0s 460us/step - loss: 0.5505 - accuracy: 0.7299\n",
      "Epoch 14/200\n",
      "804/804 [==============================] - 0s 486us/step - loss: 0.5502 - accuracy: 0.7298\n",
      "Epoch 15/200\n",
      "804/804 [==============================] - 0s 461us/step - loss: 0.5496 - accuracy: 0.7316\n",
      "Epoch 16/200\n",
      "804/804 [==============================] - 0s 453us/step - loss: 0.5494 - accuracy: 0.7311\n",
      "Epoch 17/200\n",
      "804/804 [==============================] - 0s 423us/step - loss: 0.5495 - accuracy: 0.7306\n",
      "Epoch 18/200\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5494 - accuracy: 0.7310\n",
      "Epoch 19/200\n",
      "804/804 [==============================] - 0s 411us/step - loss: 0.5491 - accuracy: 0.7309\n",
      "Epoch 20/200\n",
      "804/804 [==============================] - 0s 400us/step - loss: 0.5489 - accuracy: 0.7310\n",
      "Epoch 21/200\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5491 - accuracy: 0.7311\n",
      "Epoch 22/200\n",
      "804/804 [==============================] - 0s 424us/step - loss: 0.5486 - accuracy: 0.7306\n",
      "Epoch 23/200\n",
      "804/804 [==============================] - 0s 451us/step - loss: 0.5488 - accuracy: 0.7308\n",
      "Epoch 24/200\n",
      "804/804 [==============================] - 0s 437us/step - loss: 0.5488 - accuracy: 0.7310\n",
      "Epoch 25/200\n",
      "804/804 [==============================] - 0s 448us/step - loss: 0.5485 - accuracy: 0.7306\n",
      "Epoch 26/200\n",
      "804/804 [==============================] - 0s 438us/step - loss: 0.5485 - accuracy: 0.7318\n",
      "Epoch 27/200\n",
      "804/804 [==============================] - 0s 444us/step - loss: 0.5482 - accuracy: 0.7305\n",
      "Epoch 28/200\n",
      "804/804 [==============================] - 0s 493us/step - loss: 0.5483 - accuracy: 0.7315\n",
      "Epoch 29/200\n",
      "804/804 [==============================] - 0s 520us/step - loss: 0.5480 - accuracy: 0.7315\n",
      "Epoch 30/200\n",
      "804/804 [==============================] - 0s 428us/step - loss: 0.5481 - accuracy: 0.7317\n",
      "Epoch 31/200\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5481 - accuracy: 0.7319\n",
      "Epoch 32/200\n",
      "804/804 [==============================] - 0s 408us/step - loss: 0.5478 - accuracy: 0.7306\n",
      "Epoch 33/200\n",
      "804/804 [==============================] - 0s 420us/step - loss: 0.5479 - accuracy: 0.7312\n",
      "Epoch 34/200\n",
      "804/804 [==============================] - 0s 415us/step - loss: 0.5476 - accuracy: 0.7315\n",
      "Epoch 35/200\n",
      "804/804 [==============================] - 0s 387us/step - loss: 0.5478 - accuracy: 0.7314\n",
      "Epoch 36/200\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5477 - accuracy: 0.7313\n",
      "Epoch 37/200\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5477 - accuracy: 0.7316\n",
      "Epoch 38/200\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5474 - accuracy: 0.7307\n",
      "Epoch 39/200\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5475 - accuracy: 0.7309\n",
      "Epoch 40/200\n",
      "804/804 [==============================] - 0s 379us/step - loss: 0.5476 - accuracy: 0.7314\n",
      "Epoch 41/200\n",
      "804/804 [==============================] - 0s 380us/step - loss: 0.5472 - accuracy: 0.7312\n",
      "Epoch 42/200\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5475 - accuracy: 0.7315\n",
      "Epoch 43/200\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5472 - accuracy: 0.7320\n",
      "Epoch 44/200\n",
      "804/804 [==============================] - 0s 417us/step - loss: 0.5474 - accuracy: 0.7312\n",
      "Epoch 45/200\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5474 - accuracy: 0.7313\n",
      "Epoch 46/200\n",
      "804/804 [==============================] - 0s 384us/step - loss: 0.5474 - accuracy: 0.7305\n",
      "Epoch 47/200\n",
      "804/804 [==============================] - 0s 383us/step - loss: 0.5470 - accuracy: 0.7311\n",
      "Epoch 48/200\n",
      "804/804 [==============================] - 0s 410us/step - loss: 0.5470 - accuracy: 0.7315\n",
      "Epoch 49/200\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5470 - accuracy: 0.7306\n",
      "Epoch 50/200\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5471 - accuracy: 0.7306\n",
      "Epoch 51/200\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5467 - accuracy: 0.7314\n",
      "Epoch 52/200\n",
      "804/804 [==============================] - 0s 384us/step - loss: 0.5470 - accuracy: 0.7315\n",
      "Epoch 53/200\n",
      "804/804 [==============================] - 0s 378us/step - loss: 0.5467 - accuracy: 0.7317\n",
      "Epoch 54/200\n",
      "804/804 [==============================] - 0s 383us/step - loss: 0.5466 - accuracy: 0.7314\n",
      "Epoch 55/200\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5466 - accuracy: 0.7310\n",
      "Epoch 56/200\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5467 - accuracy: 0.7308\n",
      "Epoch 57/200\n",
      "804/804 [==============================] - 0s 476us/step - loss: 0.5467 - accuracy: 0.7316\n",
      "Epoch 58/200\n",
      "804/804 [==============================] - 0s 410us/step - loss: 0.5466 - accuracy: 0.7312\n",
      "Epoch 59/200\n",
      "804/804 [==============================] - 0s 456us/step - loss: 0.5465 - accuracy: 0.7306\n",
      "Epoch 60/200\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5463 - accuracy: 0.7317\n",
      "Epoch 61/200\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5466 - accuracy: 0.7314\n",
      "Epoch 62/200\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5465 - accuracy: 0.7307\n",
      "Epoch 63/200\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5466 - accuracy: 0.7321\n",
      "Epoch 64/200\n",
      "804/804 [==============================] - 0s 383us/step - loss: 0.5464 - accuracy: 0.7320\n",
      "Epoch 65/200\n",
      "804/804 [==============================] - 0s 423us/step - loss: 0.5465 - accuracy: 0.7311\n",
      "Epoch 66/200\n",
      "804/804 [==============================] - 0s 386us/step - loss: 0.5463 - accuracy: 0.7310\n",
      "Epoch 67/200\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5463 - accuracy: 0.7314\n",
      "Epoch 68/200\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5462 - accuracy: 0.7320\n",
      "Epoch 69/200\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5463 - accuracy: 0.7315\n",
      "Epoch 70/200\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5462 - accuracy: 0.7320\n",
      "Epoch 71/200\n",
      "804/804 [==============================] - 0s 379us/step - loss: 0.5461 - accuracy: 0.7314\n",
      "Epoch 72/200\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5464 - accuracy: 0.7310\n",
      "Epoch 73/200\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5465 - accuracy: 0.7320\n",
      "Epoch 74/200\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5462 - accuracy: 0.7311\n",
      "Epoch 75/200\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5466 - accuracy: 0.7315\n",
      "Epoch 76/200\n",
      "804/804 [==============================] - 0s 410us/step - loss: 0.5463 - accuracy: 0.7316\n",
      "Epoch 77/200\n",
      "804/804 [==============================] - 0s 380us/step - loss: 0.5461 - accuracy: 0.7324\n",
      "Epoch 78/200\n",
      "804/804 [==============================] - 0s 379us/step - loss: 0.5462 - accuracy: 0.7324\n",
      "Epoch 79/200\n",
      "804/804 [==============================] - 0s 382us/step - loss: 0.5463 - accuracy: 0.7318\n",
      "Epoch 80/200\n",
      "804/804 [==============================] - 0s 465us/step - loss: 0.5460 - accuracy: 0.7319\n",
      "Epoch 81/200\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5465 - accuracy: 0.7315\n",
      "Epoch 82/200\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5459 - accuracy: 0.7324\n",
      "Epoch 83/200\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5462 - accuracy: 0.7319\n",
      "Epoch 84/200\n",
      "804/804 [==============================] - 0s 382us/step - loss: 0.5462 - accuracy: 0.7318\n",
      "Epoch 85/200\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5460 - accuracy: 0.7311\n",
      "Epoch 86/200\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5461 - accuracy: 0.7315\n",
      "Epoch 87/200\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5463 - accuracy: 0.7315\n",
      "Epoch 88/200\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5461 - accuracy: 0.7318\n",
      "Epoch 89/200\n",
      "804/804 [==============================] - 0s 382us/step - loss: 0.5460 - accuracy: 0.7317\n",
      "Epoch 90/200\n",
      "804/804 [==============================] - 0s 375us/step - loss: 0.5459 - accuracy: 0.7311\n",
      "Epoch 91/200\n",
      "804/804 [==============================] - 0s 384us/step - loss: 0.5464 - accuracy: 0.7310\n",
      "Epoch 92/200\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5458 - accuracy: 0.7305\n",
      "Epoch 93/200\n",
      "804/804 [==============================] - 0s 450us/step - loss: 0.5462 - accuracy: 0.7312\n",
      "Epoch 94/200\n",
      "804/804 [==============================] - 0s 405us/step - loss: 0.5458 - accuracy: 0.7315\n",
      "Epoch 95/200\n",
      "804/804 [==============================] - 0s 427us/step - loss: 0.5462 - accuracy: 0.7310\n",
      "Epoch 96/200\n",
      "804/804 [==============================] - 0s 427us/step - loss: 0.5459 - accuracy: 0.7313\n",
      "Epoch 97/200\n",
      "804/804 [==============================] - 0s 413us/step - loss: 0.5458 - accuracy: 0.7317\n",
      "Epoch 98/200\n",
      "804/804 [==============================] - 0s 405us/step - loss: 0.5461 - accuracy: 0.7320\n",
      "Epoch 99/200\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5457 - accuracy: 0.7327\n",
      "Epoch 100/200\n",
      "804/804 [==============================] - 0s 405us/step - loss: 0.5460 - accuracy: 0.7311\n",
      "Epoch 101/200\n",
      "804/804 [==============================] - 0s 383us/step - loss: 0.5457 - accuracy: 0.7315\n",
      "Epoch 102/200\n",
      "804/804 [==============================] - 0s 380us/step - loss: 0.5460 - accuracy: 0.7319\n",
      "Epoch 103/200\n",
      "804/804 [==============================] - 0s 384us/step - loss: 0.5459 - accuracy: 0.7313\n",
      "Epoch 104/200\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5461 - accuracy: 0.7307\n",
      "Epoch 105/200\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5457 - accuracy: 0.7312\n",
      "Epoch 106/200\n",
      "804/804 [==============================] - 0s 384us/step - loss: 0.5458 - accuracy: 0.7314\n",
      "Epoch 107/200\n",
      "804/804 [==============================] - 0s 387us/step - loss: 0.5457 - accuracy: 0.7313\n",
      "Epoch 108/200\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5459 - accuracy: 0.7313\n",
      "Epoch 109/200\n",
      "804/804 [==============================] - 0s 381us/step - loss: 0.5458 - accuracy: 0.7310\n",
      "Epoch 110/200\n",
      "804/804 [==============================] - 0s 384us/step - loss: 0.5458 - accuracy: 0.7310\n",
      "Epoch 111/200\n",
      "804/804 [==============================] - 0s 440us/step - loss: 0.5457 - accuracy: 0.7317\n",
      "Epoch 112/200\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5457 - accuracy: 0.7310\n",
      "Epoch 113/200\n",
      "804/804 [==============================] - 0s 437us/step - loss: 0.5456 - accuracy: 0.7307\n",
      "Epoch 114/200\n",
      "804/804 [==============================] - 0s 458us/step - loss: 0.5455 - accuracy: 0.7316\n",
      "Epoch 115/200\n",
      "804/804 [==============================] - 0s 449us/step - loss: 0.5456 - accuracy: 0.7313\n",
      "Epoch 116/200\n",
      "804/804 [==============================] - 0s 448us/step - loss: 0.5456 - accuracy: 0.7309\n",
      "Epoch 117/200\n",
      "804/804 [==============================] - 0s 452us/step - loss: 0.5455 - accuracy: 0.7313\n",
      "Epoch 118/200\n",
      "804/804 [==============================] - 0s 464us/step - loss: 0.5458 - accuracy: 0.7310\n",
      "Epoch 119/200\n",
      "804/804 [==============================] - 0s 424us/step - loss: 0.5456 - accuracy: 0.7309\n",
      "Epoch 120/200\n",
      "804/804 [==============================] - 0s 430us/step - loss: 0.5454 - accuracy: 0.7311\n",
      "Epoch 121/200\n",
      "804/804 [==============================] - 0s 425us/step - loss: 0.5457 - accuracy: 0.7317\n",
      "Epoch 122/200\n",
      "804/804 [==============================] - 0s 441us/step - loss: 0.5458 - accuracy: 0.7308\n",
      "Epoch 123/200\n",
      "804/804 [==============================] - 0s 445us/step - loss: 0.5456 - accuracy: 0.7317\n",
      "Epoch 124/200\n",
      "804/804 [==============================] - 0s 440us/step - loss: 0.5455 - accuracy: 0.7315\n",
      "Epoch 125/200\n",
      "804/804 [==============================] - 0s 423us/step - loss: 0.5452 - accuracy: 0.7313\n",
      "Epoch 126/200\n",
      "804/804 [==============================] - 0s 441us/step - loss: 0.5454 - accuracy: 0.7315\n",
      "Epoch 127/200\n",
      "804/804 [==============================] - 0s 459us/step - loss: 0.5452 - accuracy: 0.7314\n",
      "Epoch 128/200\n",
      "804/804 [==============================] - 0s 453us/step - loss: 0.5454 - accuracy: 0.7317\n",
      "Epoch 129/200\n",
      "804/804 [==============================] - 0s 440us/step - loss: 0.5452 - accuracy: 0.7330\n",
      "Epoch 130/200\n",
      "804/804 [==============================] - 0s 438us/step - loss: 0.5453 - accuracy: 0.7318\n",
      "Epoch 131/200\n",
      "804/804 [==============================] - 0s 421us/step - loss: 0.5453 - accuracy: 0.7311\n",
      "Epoch 132/200\n",
      "804/804 [==============================] - 0s 428us/step - loss: 0.5452 - accuracy: 0.7314\n",
      "Epoch 133/200\n",
      "804/804 [==============================] - 0s 435us/step - loss: 0.5453 - accuracy: 0.7321\n",
      "Epoch 134/200\n",
      "804/804 [==============================] - 0s 452us/step - loss: 0.5452 - accuracy: 0.7315\n",
      "Epoch 135/200\n",
      "804/804 [==============================] - 0s 457us/step - loss: 0.5451 - accuracy: 0.7326\n",
      "Epoch 136/200\n",
      "804/804 [==============================] - 0s 419us/step - loss: 0.5453 - accuracy: 0.7315\n",
      "Epoch 137/200\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5452 - accuracy: 0.7317\n",
      "Epoch 138/200\n",
      "804/804 [==============================] - 0s 382us/step - loss: 0.5452 - accuracy: 0.7323\n",
      "Epoch 139/200\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5454 - accuracy: 0.7319\n",
      "Epoch 140/200\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5450 - accuracy: 0.7323\n",
      "Epoch 141/200\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5454 - accuracy: 0.7306\n",
      "Epoch 142/200\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5452 - accuracy: 0.7316\n",
      "Epoch 143/200\n",
      "804/804 [==============================] - 0s 381us/step - loss: 0.5449 - accuracy: 0.7312\n",
      "Epoch 144/200\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5451 - accuracy: 0.7311\n",
      "Epoch 145/200\n",
      "804/804 [==============================] - 0s 383us/step - loss: 0.5453 - accuracy: 0.7318\n",
      "Epoch 146/200\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5451 - accuracy: 0.7313\n",
      "Epoch 147/200\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5451 - accuracy: 0.7321\n",
      "Epoch 148/200\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5451 - accuracy: 0.7322\n",
      "Epoch 149/200\n",
      "804/804 [==============================] - 0s 383us/step - loss: 0.5451 - accuracy: 0.7315\n",
      "Epoch 150/200\n",
      "804/804 [==============================] - 0s 376us/step - loss: 0.5449 - accuracy: 0.7328\n",
      "Epoch 151/200\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5451 - accuracy: 0.7321\n",
      "Epoch 152/200\n",
      "804/804 [==============================] - 0s 433us/step - loss: 0.5452 - accuracy: 0.7314\n",
      "Epoch 153/200\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5452 - accuracy: 0.7317\n",
      "Epoch 154/200\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5449 - accuracy: 0.7320\n",
      "Epoch 155/200\n",
      "804/804 [==============================] - 0s 384us/step - loss: 0.5452 - accuracy: 0.7313\n",
      "Epoch 156/200\n",
      "804/804 [==============================] - 0s 381us/step - loss: 0.5451 - accuracy: 0.7324\n",
      "Epoch 157/200\n",
      "804/804 [==============================] - 0s 381us/step - loss: 0.5451 - accuracy: 0.7317\n",
      "Epoch 158/200\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5448 - accuracy: 0.7320\n",
      "Epoch 159/200\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5447 - accuracy: 0.7325\n",
      "Epoch 160/200\n",
      "804/804 [==============================] - 0s 406us/step - loss: 0.5450 - accuracy: 0.7317\n",
      "Epoch 161/200\n",
      "804/804 [==============================] - 0s 383us/step - loss: 0.5448 - accuracy: 0.7316\n",
      "Epoch 162/200\n",
      "804/804 [==============================] - 0s 383us/step - loss: 0.5448 - accuracy: 0.7323\n",
      "Epoch 163/200\n",
      "804/804 [==============================] - 0s 383us/step - loss: 0.5448 - accuracy: 0.7320\n",
      "Epoch 164/200\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5448 - accuracy: 0.7316\n",
      "Epoch 165/200\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5449 - accuracy: 0.7314\n",
      "Epoch 166/200\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5451 - accuracy: 0.7318\n",
      "Epoch 167/200\n",
      "804/804 [==============================] - 0s 410us/step - loss: 0.5449 - accuracy: 0.7317\n",
      "Epoch 168/200\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5447 - accuracy: 0.7322\n",
      "Epoch 169/200\n",
      "804/804 [==============================] - 0s 382us/step - loss: 0.5448 - accuracy: 0.7320\n",
      "Epoch 170/200\n",
      "804/804 [==============================] - 0s 380us/step - loss: 0.5447 - accuracy: 0.7322\n",
      "Epoch 171/200\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5449 - accuracy: 0.7322\n",
      "Epoch 172/200\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5450 - accuracy: 0.7320\n",
      "Epoch 173/200\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5451 - accuracy: 0.7320\n",
      "Epoch 174/200\n",
      "804/804 [==============================] - 0s 407us/step - loss: 0.5448 - accuracy: 0.7329\n",
      "Epoch 175/200\n",
      "804/804 [==============================] - 0s 383us/step - loss: 0.5450 - accuracy: 0.7311\n",
      "Epoch 176/200\n",
      "804/804 [==============================] - 0s 380us/step - loss: 0.5450 - accuracy: 0.7317\n",
      "Epoch 177/200\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5450 - accuracy: 0.7319\n",
      "Epoch 178/200\n",
      "804/804 [==============================] - 0s 384us/step - loss: 0.5450 - accuracy: 0.7310\n",
      "Epoch 179/200\n",
      "804/804 [==============================] - 0s 402us/step - loss: 0.5449 - accuracy: 0.7311\n",
      "Epoch 180/200\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5451 - accuracy: 0.7317\n",
      "Epoch 181/200\n",
      "804/804 [==============================] - 0s 405us/step - loss: 0.5448 - accuracy: 0.7321\n",
      "Epoch 182/200\n",
      "804/804 [==============================] - 0s 385us/step - loss: 0.5447 - accuracy: 0.7311\n",
      "Epoch 183/200\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5448 - accuracy: 0.7322\n",
      "Epoch 184/200\n",
      "804/804 [==============================] - 0s 410us/step - loss: 0.5447 - accuracy: 0.7319\n",
      "Epoch 185/200\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5446 - accuracy: 0.7313\n",
      "Epoch 186/200\n",
      "804/804 [==============================] - 0s 405us/step - loss: 0.5446 - accuracy: 0.7313\n",
      "Epoch 187/200\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5448 - accuracy: 0.7313\n",
      "Epoch 188/200\n",
      "804/804 [==============================] - 0s 409us/step - loss: 0.5448 - accuracy: 0.7314\n",
      "Epoch 189/200\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5446 - accuracy: 0.7316\n",
      "Epoch 190/200\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5449 - accuracy: 0.7317\n",
      "Epoch 191/200\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5447 - accuracy: 0.7323\n",
      "Epoch 192/200\n",
      "804/804 [==============================] - 0s 402us/step - loss: 0.5448 - accuracy: 0.7320\n",
      "Epoch 193/200\n",
      "804/804 [==============================] - 0s 443us/step - loss: 0.5448 - accuracy: 0.7321\n",
      "Epoch 194/200\n",
      "804/804 [==============================] - 0s 400us/step - loss: 0.5445 - accuracy: 0.7315\n",
      "Epoch 195/200\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5448 - accuracy: 0.7324\n",
      "Epoch 196/200\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5448 - accuracy: 0.7317\n",
      "Epoch 197/200\n",
      "804/804 [==============================] - 0s 406us/step - loss: 0.5448 - accuracy: 0.7322\n",
      "Epoch 198/200\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5448 - accuracy: 0.7317\n",
      "Epoch 199/200\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5444 - accuracy: 0.7324\n",
      "Epoch 200/200\n",
      "804/804 [==============================] - 0s 402us/step - loss: 0.5448 - accuracy: 0.7317\n"
     ]
    }
   ],
   "source": [
    "fit_nn3 = nn3.fit(X_train_scaled, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5514 - accuracy: 0.7268 - 247ms/epoch - 923us/step\n",
      "Loss: 0.5513572096824646, Accuracy: 0.7267638444900513\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn3.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1402d149c88>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df3 = pd.DataFrame(fit_nn3.history)\n",
    "\n",
    "# Increase the index by 1 to match the number of epochs\n",
    "history_df3.index += 1\n",
    "\n",
    "# Plot the loss\n",
    "history_df3.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model revision 3 accuracy = 0.7267"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Revision 4 increase nodes in layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_58 (Dense)            (None, 8)                 400       \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 553\n",
      "Trainable params: 553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn4 = tf.keras.models.Sequential()\n",
    "\n",
    "input_features = len(X_train_scaled[0])\n",
    "\n",
    "# Add our first Dense layer, including the input layer\n",
    "nn4.add(tf.keras.layers.Dense(units=8, activation=\"relu\", input_dim=input_features))\n",
    "\n",
    "nn4.add(tf.keras.layers.Dense(units=8, activation='relu'))\n",
    "\n",
    "nn4.add(tf.keras.layers.Dense(units=8, activation='relu'))\n",
    "\n",
    "# Add the output layer that uses a probability activation function\n",
    "nn4.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Check the structure of the Sequential model\n",
    "nn4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn4.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"], steps_per_execution = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.6215 - accuracy: 0.6784\n",
      "Epoch 2/200\n",
      "804/804 [==============================] - 0s 431us/step - loss: 0.5705 - accuracy: 0.7193\n",
      "Epoch 3/200\n",
      "804/804 [==============================] - 0s 360us/step - loss: 0.5605 - accuracy: 0.7253\n",
      "Epoch 4/200\n",
      "804/804 [==============================] - 0s 367us/step - loss: 0.5568 - accuracy: 0.7281\n",
      "Epoch 5/200\n",
      "804/804 [==============================] - 0s 361us/step - loss: 0.5538 - accuracy: 0.7280\n",
      "Epoch 6/200\n",
      "804/804 [==============================] - 0s 365us/step - loss: 0.5526 - accuracy: 0.7302\n",
      "Epoch 7/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5510 - accuracy: 0.7296\n",
      "Epoch 8/200\n",
      "804/804 [==============================] - 0s 367us/step - loss: 0.5500 - accuracy: 0.7304\n",
      "Epoch 9/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5487 - accuracy: 0.7311\n",
      "Epoch 10/200\n",
      "804/804 [==============================] - 0s 363us/step - loss: 0.5483 - accuracy: 0.7315\n",
      "Epoch 11/200\n",
      "804/804 [==============================] - 0s 364us/step - loss: 0.5474 - accuracy: 0.7320\n",
      "Epoch 12/200\n",
      "804/804 [==============================] - 0s 363us/step - loss: 0.5469 - accuracy: 0.7321\n",
      "Epoch 13/200\n",
      "804/804 [==============================] - 0s 387us/step - loss: 0.5463 - accuracy: 0.7317\n",
      "Epoch 14/200\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5459 - accuracy: 0.7334\n",
      "Epoch 15/200\n",
      "804/804 [==============================] - 0s 368us/step - loss: 0.5450 - accuracy: 0.7325\n",
      "Epoch 16/200\n",
      "804/804 [==============================] - 0s 447us/step - loss: 0.5448 - accuracy: 0.7323\n",
      "Epoch 17/200\n",
      "804/804 [==============================] - 0s 386us/step - loss: 0.5443 - accuracy: 0.7335\n",
      "Epoch 18/200\n",
      "804/804 [==============================] - 0s 402us/step - loss: 0.5439 - accuracy: 0.7330\n",
      "Epoch 19/200\n",
      "804/804 [==============================] - 0s 408us/step - loss: 0.5436 - accuracy: 0.7328\n",
      "Epoch 20/200\n",
      "804/804 [==============================] - 0s 369us/step - loss: 0.5433 - accuracy: 0.7333\n",
      "Epoch 21/200\n",
      "804/804 [==============================] - 0s 371us/step - loss: 0.5435 - accuracy: 0.7337\n",
      "Epoch 22/200\n",
      "804/804 [==============================] - 0s 443us/step - loss: 0.5427 - accuracy: 0.7334\n",
      "Epoch 23/200\n",
      "804/804 [==============================] - 0s 405us/step - loss: 0.5425 - accuracy: 0.7344\n",
      "Epoch 24/200\n",
      "804/804 [==============================] - 0s 362us/step - loss: 0.5429 - accuracy: 0.7327\n",
      "Epoch 25/200\n",
      "804/804 [==============================] - 0s 358us/step - loss: 0.5426 - accuracy: 0.7338\n",
      "Epoch 26/200\n",
      "804/804 [==============================] - 0s 365us/step - loss: 0.5420 - accuracy: 0.7343\n",
      "Epoch 27/200\n",
      "804/804 [==============================] - 0s 354us/step - loss: 0.5419 - accuracy: 0.7336\n",
      "Epoch 28/200\n",
      "804/804 [==============================] - 0s 358us/step - loss: 0.5419 - accuracy: 0.7338\n",
      "Epoch 29/200\n",
      "804/804 [==============================] - 0s 354us/step - loss: 0.5413 - accuracy: 0.7348\n",
      "Epoch 30/200\n",
      "804/804 [==============================] - 0s 366us/step - loss: 0.5413 - accuracy: 0.7337\n",
      "Epoch 31/200\n",
      "804/804 [==============================] - 0s 358us/step - loss: 0.5412 - accuracy: 0.7352\n",
      "Epoch 32/200\n",
      "804/804 [==============================] - 0s 364us/step - loss: 0.5410 - accuracy: 0.7355\n",
      "Epoch 33/200\n",
      "804/804 [==============================] - 0s 357us/step - loss: 0.5413 - accuracy: 0.7336\n",
      "Epoch 34/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5408 - accuracy: 0.7346\n",
      "Epoch 35/200\n",
      "804/804 [==============================] - 0s 354us/step - loss: 0.5407 - accuracy: 0.7343\n",
      "Epoch 36/200\n",
      "804/804 [==============================] - 0s 350us/step - loss: 0.5407 - accuracy: 0.7346\n",
      "Epoch 37/200\n",
      "804/804 [==============================] - 0s 372us/step - loss: 0.5410 - accuracy: 0.7356\n",
      "Epoch 38/200\n",
      "804/804 [==============================] - 0s 373us/step - loss: 0.5409 - accuracy: 0.7343\n",
      "Epoch 39/200\n",
      "804/804 [==============================] - 0s 358us/step - loss: 0.5405 - accuracy: 0.7348\n",
      "Epoch 40/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5404 - accuracy: 0.7356\n",
      "Epoch 41/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5406 - accuracy: 0.7342\n",
      "Epoch 42/200\n",
      "804/804 [==============================] - 0s 354us/step - loss: 0.5404 - accuracy: 0.7354\n",
      "Epoch 43/200\n",
      "804/804 [==============================] - 0s 357us/step - loss: 0.5404 - accuracy: 0.7342\n",
      "Epoch 44/200\n",
      "804/804 [==============================] - 0s 366us/step - loss: 0.5401 - accuracy: 0.7347\n",
      "Epoch 45/200\n",
      "804/804 [==============================] - 0s 358us/step - loss: 0.5401 - accuracy: 0.7350\n",
      "Epoch 46/200\n",
      "804/804 [==============================] - 0s 369us/step - loss: 0.5406 - accuracy: 0.7349\n",
      "Epoch 47/200\n",
      "804/804 [==============================] - 0s 352us/step - loss: 0.5402 - accuracy: 0.7350\n",
      "Epoch 48/200\n",
      "804/804 [==============================] - 0s 349us/step - loss: 0.5398 - accuracy: 0.7360\n",
      "Epoch 49/200\n",
      "804/804 [==============================] - 0s 357us/step - loss: 0.5401 - accuracy: 0.7351\n",
      "Epoch 50/200\n",
      "804/804 [==============================] - 0s 366us/step - loss: 0.5400 - accuracy: 0.7350\n",
      "Epoch 51/200\n",
      "804/804 [==============================] - 0s 382us/step - loss: 0.5399 - accuracy: 0.7348\n",
      "Epoch 52/200\n",
      "804/804 [==============================] - 0s 371us/step - loss: 0.5393 - accuracy: 0.7359\n",
      "Epoch 53/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5397 - accuracy: 0.7341\n",
      "Epoch 54/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5398 - accuracy: 0.7343\n",
      "Epoch 55/200\n",
      "804/804 [==============================] - 0s 351us/step - loss: 0.5393 - accuracy: 0.7349\n",
      "Epoch 56/200\n",
      "804/804 [==============================] - 0s 353us/step - loss: 0.5395 - accuracy: 0.7343\n",
      "Epoch 57/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5393 - accuracy: 0.7357\n",
      "Epoch 58/200\n",
      "804/804 [==============================] - 0s 361us/step - loss: 0.5393 - accuracy: 0.7352\n",
      "Epoch 59/200\n",
      "804/804 [==============================] - 0s 365us/step - loss: 0.5394 - accuracy: 0.7340\n",
      "Epoch 60/200\n",
      "804/804 [==============================] - 0s 360us/step - loss: 0.5390 - accuracy: 0.7351\n",
      "Epoch 61/200\n",
      "804/804 [==============================] - 0s 357us/step - loss: 0.5387 - accuracy: 0.7354\n",
      "Epoch 62/200\n",
      "804/804 [==============================] - 0s 350us/step - loss: 0.5390 - accuracy: 0.7362\n",
      "Epoch 63/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5388 - accuracy: 0.7357\n",
      "Epoch 64/200\n",
      "804/804 [==============================] - 0s 373us/step - loss: 0.5387 - accuracy: 0.7353\n",
      "Epoch 65/200\n",
      "804/804 [==============================] - 0s 363us/step - loss: 0.5392 - accuracy: 0.7362\n",
      "Epoch 66/200\n",
      "804/804 [==============================] - 0s 379us/step - loss: 0.5388 - accuracy: 0.7337\n",
      "Epoch 67/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5386 - accuracy: 0.7354\n",
      "Epoch 68/200\n",
      "804/804 [==============================] - 0s 375us/step - loss: 0.5385 - accuracy: 0.7353\n",
      "Epoch 69/200\n",
      "804/804 [==============================] - 0s 354us/step - loss: 0.5383 - accuracy: 0.7365\n",
      "Epoch 70/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5384 - accuracy: 0.7343\n",
      "Epoch 71/200\n",
      "804/804 [==============================] - 0s 361us/step - loss: 0.5385 - accuracy: 0.7350\n",
      "Epoch 72/200\n",
      "804/804 [==============================] - 0s 357us/step - loss: 0.5383 - accuracy: 0.7367\n",
      "Epoch 73/200\n",
      "804/804 [==============================] - 0s 360us/step - loss: 0.5383 - accuracy: 0.7352\n",
      "Epoch 74/200\n",
      "804/804 [==============================] - 0s 361us/step - loss: 0.5384 - accuracy: 0.7360\n",
      "Epoch 75/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5378 - accuracy: 0.7350\n",
      "Epoch 76/200\n",
      "804/804 [==============================] - 0s 354us/step - loss: 0.5387 - accuracy: 0.7348\n",
      "Epoch 77/200\n",
      "804/804 [==============================] - 0s 349us/step - loss: 0.5380 - accuracy: 0.7358\n",
      "Epoch 78/200\n",
      "804/804 [==============================] - 0s 375us/step - loss: 0.5384 - accuracy: 0.7362\n",
      "Epoch 79/200\n",
      "804/804 [==============================] - 0s 357us/step - loss: 0.5378 - accuracy: 0.7369\n",
      "Epoch 80/200\n",
      "804/804 [==============================] - 0s 362us/step - loss: 0.5376 - accuracy: 0.7364\n",
      "Epoch 81/200\n",
      "804/804 [==============================] - 0s 372us/step - loss: 0.5377 - accuracy: 0.7360\n",
      "Epoch 82/200\n",
      "804/804 [==============================] - 0s 354us/step - loss: 0.5381 - accuracy: 0.7374\n",
      "Epoch 83/200\n",
      "804/804 [==============================] - 0s 352us/step - loss: 0.5375 - accuracy: 0.7359\n",
      "Epoch 84/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5378 - accuracy: 0.7368\n",
      "Epoch 85/200\n",
      "804/804 [==============================] - 0s 357us/step - loss: 0.5375 - accuracy: 0.7367\n",
      "Epoch 86/200\n",
      "804/804 [==============================] - 0s 358us/step - loss: 0.5373 - accuracy: 0.7364\n",
      "Epoch 87/200\n",
      "804/804 [==============================] - 0s 362us/step - loss: 0.5376 - accuracy: 0.7371\n",
      "Epoch 88/200\n",
      "804/804 [==============================] - 0s 359us/step - loss: 0.5377 - accuracy: 0.7365\n",
      "Epoch 89/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5371 - accuracy: 0.7360\n",
      "Epoch 90/200\n",
      "804/804 [==============================] - 0s 353us/step - loss: 0.5372 - accuracy: 0.7377\n",
      "Epoch 91/200\n",
      "804/804 [==============================] - 0s 349us/step - loss: 0.5376 - accuracy: 0.7369\n",
      "Epoch 92/200\n",
      "804/804 [==============================] - 0s 376us/step - loss: 0.5372 - accuracy: 0.7365\n",
      "Epoch 93/200\n",
      "804/804 [==============================] - 0s 364us/step - loss: 0.5377 - accuracy: 0.7366\n",
      "Epoch 94/200\n",
      "804/804 [==============================] - 0s 363us/step - loss: 0.5371 - accuracy: 0.7372\n",
      "Epoch 95/200\n",
      "804/804 [==============================] - 0s 372us/step - loss: 0.5373 - accuracy: 0.7362\n",
      "Epoch 96/200\n",
      "804/804 [==============================] - 0s 358us/step - loss: 0.5372 - accuracy: 0.7377\n",
      "Epoch 97/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5373 - accuracy: 0.7364\n",
      "Epoch 98/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5371 - accuracy: 0.7362\n",
      "Epoch 99/200\n",
      "804/804 [==============================] - 0s 360us/step - loss: 0.5369 - accuracy: 0.7374\n",
      "Epoch 100/200\n",
      "804/804 [==============================] - 0s 359us/step - loss: 0.5372 - accuracy: 0.7357\n",
      "Epoch 101/200\n",
      "804/804 [==============================] - 0s 362us/step - loss: 0.5372 - accuracy: 0.7379\n",
      "Epoch 102/200\n",
      "804/804 [==============================] - 0s 361us/step - loss: 0.5370 - accuracy: 0.7375\n",
      "Epoch 103/200\n",
      "804/804 [==============================] - 0s 362us/step - loss: 0.5369 - accuracy: 0.7372\n",
      "Epoch 104/200\n",
      "804/804 [==============================] - 0s 366us/step - loss: 0.5373 - accuracy: 0.7367\n",
      "Epoch 105/200\n",
      "804/804 [==============================] - 0s 354us/step - loss: 0.5369 - accuracy: 0.7370\n",
      "Epoch 106/200\n",
      "804/804 [==============================] - 0s 379us/step - loss: 0.5368 - accuracy: 0.7376\n",
      "Epoch 107/200\n",
      "804/804 [==============================] - 0s 362us/step - loss: 0.5368 - accuracy: 0.7378\n",
      "Epoch 108/200\n",
      "804/804 [==============================] - 0s 362us/step - loss: 0.5365 - accuracy: 0.7370\n",
      "Epoch 109/200\n",
      "804/804 [==============================] - 0s 416us/step - loss: 0.5369 - accuracy: 0.7375\n",
      "Epoch 110/200\n",
      "804/804 [==============================] - 0s 371us/step - loss: 0.5367 - accuracy: 0.7397\n",
      "Epoch 111/200\n",
      "804/804 [==============================] - 0s 352us/step - loss: 0.5367 - accuracy: 0.7374\n",
      "Epoch 112/200\n",
      "804/804 [==============================] - 0s 359us/step - loss: 0.5368 - accuracy: 0.7385\n",
      "Epoch 113/200\n",
      "804/804 [==============================] - 0s 368us/step - loss: 0.5370 - accuracy: 0.7390\n",
      "Epoch 114/200\n",
      "804/804 [==============================] - 0s 362us/step - loss: 0.5368 - accuracy: 0.7381\n",
      "Epoch 115/200\n",
      "804/804 [==============================] - 0s 375us/step - loss: 0.5367 - accuracy: 0.7376\n",
      "Epoch 116/200\n",
      "804/804 [==============================] - 0s 352us/step - loss: 0.5366 - accuracy: 0.7379\n",
      "Epoch 117/200\n",
      "804/804 [==============================] - 0s 354us/step - loss: 0.5365 - accuracy: 0.7371\n",
      "Epoch 118/200\n",
      "804/804 [==============================] - 0s 353us/step - loss: 0.5365 - accuracy: 0.7376\n",
      "Epoch 119/200\n",
      "804/804 [==============================] - 0s 360us/step - loss: 0.5365 - accuracy: 0.7377\n",
      "Epoch 120/200\n",
      "804/804 [==============================] - 0s 364us/step - loss: 0.5366 - accuracy: 0.7382\n",
      "Epoch 121/200\n",
      "804/804 [==============================] - 0s 367us/step - loss: 0.5367 - accuracy: 0.7374\n",
      "Epoch 122/200\n",
      "804/804 [==============================] - 0s 366us/step - loss: 0.5363 - accuracy: 0.7381\n",
      "Epoch 123/200\n",
      "804/804 [==============================] - 0s 351us/step - loss: 0.5364 - accuracy: 0.7375\n",
      "Epoch 124/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5365 - accuracy: 0.7376\n",
      "Epoch 125/200\n",
      "804/804 [==============================] - 0s 354us/step - loss: 0.5363 - accuracy: 0.7383\n",
      "Epoch 126/200\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5361 - accuracy: 0.7376\n",
      "Epoch 127/200\n",
      "804/804 [==============================] - 0s 359us/step - loss: 0.5364 - accuracy: 0.7377\n",
      "Epoch 128/200\n",
      "804/804 [==============================] - 0s 362us/step - loss: 0.5363 - accuracy: 0.7374\n",
      "Epoch 129/200\n",
      "804/804 [==============================] - 0s 365us/step - loss: 0.5358 - accuracy: 0.7375\n",
      "Epoch 130/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5361 - accuracy: 0.7369\n",
      "Epoch 131/200\n",
      "804/804 [==============================] - 0s 352us/step - loss: 0.5357 - accuracy: 0.7385\n",
      "Epoch 132/200\n",
      "804/804 [==============================] - 0s 349us/step - loss: 0.5362 - accuracy: 0.7376\n",
      "Epoch 133/200\n",
      "804/804 [==============================] - 0s 360us/step - loss: 0.5358 - accuracy: 0.7376\n",
      "Epoch 134/200\n",
      "804/804 [==============================] - 0s 366us/step - loss: 0.5358 - accuracy: 0.7380\n",
      "Epoch 135/200\n",
      "804/804 [==============================] - 0s 370us/step - loss: 0.5360 - accuracy: 0.7377\n",
      "Epoch 136/200\n",
      "804/804 [==============================] - 0s 357us/step - loss: 0.5359 - accuracy: 0.7379\n",
      "Epoch 137/200\n",
      "804/804 [==============================] - 0s 350us/step - loss: 0.5359 - accuracy: 0.7380\n",
      "Epoch 138/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5357 - accuracy: 0.7370\n",
      "Epoch 139/200\n",
      "804/804 [==============================] - 0s 364us/step - loss: 0.5359 - accuracy: 0.7378\n",
      "Epoch 140/200\n",
      "804/804 [==============================] - 0s 365us/step - loss: 0.5361 - accuracy: 0.7386\n",
      "Epoch 141/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5359 - accuracy: 0.7368\n",
      "Epoch 142/200\n",
      "804/804 [==============================] - 0s 362us/step - loss: 0.5357 - accuracy: 0.7385\n",
      "Epoch 143/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5359 - accuracy: 0.7387\n",
      "Epoch 144/200\n",
      "804/804 [==============================] - 0s 374us/step - loss: 0.5358 - accuracy: 0.7378\n",
      "Epoch 145/200\n",
      "804/804 [==============================] - 0s 351us/step - loss: 0.5358 - accuracy: 0.7389\n",
      "Epoch 146/200\n",
      "804/804 [==============================] - 0s 357us/step - loss: 0.5360 - accuracy: 0.7378\n",
      "Epoch 147/200\n",
      "804/804 [==============================] - 0s 363us/step - loss: 0.5358 - accuracy: 0.7380\n",
      "Epoch 148/200\n",
      "804/804 [==============================] - 0s 359us/step - loss: 0.5358 - accuracy: 0.7386\n",
      "Epoch 149/200\n",
      "804/804 [==============================] - 0s 362us/step - loss: 0.5359 - accuracy: 0.7379\n",
      "Epoch 150/200\n",
      "804/804 [==============================] - 0s 358us/step - loss: 0.5355 - accuracy: 0.7376\n",
      "Epoch 151/200\n",
      "804/804 [==============================] - 0s 359us/step - loss: 0.5357 - accuracy: 0.7372\n",
      "Epoch 152/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5352 - accuracy: 0.7397\n",
      "Epoch 153/200\n",
      "804/804 [==============================] - 0s 376us/step - loss: 0.5356 - accuracy: 0.7381\n",
      "Epoch 154/200\n",
      "804/804 [==============================] - 0s 433us/step - loss: 0.5356 - accuracy: 0.7378\n",
      "Epoch 155/200\n",
      "804/804 [==============================] - 0s 467us/step - loss: 0.5354 - accuracy: 0.7380\n",
      "Epoch 156/200\n",
      "804/804 [==============================] - 0s 369us/step - loss: 0.5356 - accuracy: 0.7379\n",
      "Epoch 157/200\n",
      "804/804 [==============================] - 0s 350us/step - loss: 0.5357 - accuracy: 0.7372\n",
      "Epoch 158/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5352 - accuracy: 0.7384\n",
      "Epoch 159/200\n",
      "804/804 [==============================] - 0s 354us/step - loss: 0.5352 - accuracy: 0.7379\n",
      "Epoch 160/200\n",
      "804/804 [==============================] - 0s 373us/step - loss: 0.5354 - accuracy: 0.7385\n",
      "Epoch 161/200\n",
      "804/804 [==============================] - 0s 365us/step - loss: 0.5353 - accuracy: 0.7376\n",
      "Epoch 162/200\n",
      "804/804 [==============================] - 0s 363us/step - loss: 0.5355 - accuracy: 0.7378\n",
      "Epoch 163/200\n",
      "804/804 [==============================] - 0s 363us/step - loss: 0.5356 - accuracy: 0.7383\n",
      "Epoch 164/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5353 - accuracy: 0.7385\n",
      "Epoch 165/200\n",
      "804/804 [==============================] - 0s 358us/step - loss: 0.5355 - accuracy: 0.7379\n",
      "Epoch 166/200\n",
      "804/804 [==============================] - 0s 362us/step - loss: 0.5356 - accuracy: 0.7374\n",
      "Epoch 167/200\n",
      "804/804 [==============================] - 0s 358us/step - loss: 0.5355 - accuracy: 0.7388\n",
      "Epoch 168/200\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5352 - accuracy: 0.7383\n",
      "Epoch 169/200\n",
      "804/804 [==============================] - 0s 358us/step - loss: 0.5351 - accuracy: 0.7384\n",
      "Epoch 170/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5353 - accuracy: 0.7386\n",
      "Epoch 171/200\n",
      "804/804 [==============================] - 0s 359us/step - loss: 0.5352 - accuracy: 0.7380\n",
      "Epoch 172/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5352 - accuracy: 0.7385\n",
      "Epoch 173/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5354 - accuracy: 0.7385\n",
      "Epoch 174/200\n",
      "804/804 [==============================] - 0s 364us/step - loss: 0.5351 - accuracy: 0.7383\n",
      "Epoch 175/200\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5354 - accuracy: 0.7376\n",
      "Epoch 176/200\n",
      "804/804 [==============================] - 0s 364us/step - loss: 0.5353 - accuracy: 0.7391\n",
      "Epoch 177/200\n",
      "804/804 [==============================] - 0s 351us/step - loss: 0.5353 - accuracy: 0.7378\n",
      "Epoch 178/200\n",
      "804/804 [==============================] - 0s 358us/step - loss: 0.5350 - accuracy: 0.7383\n",
      "Epoch 179/200\n",
      "804/804 [==============================] - 0s 358us/step - loss: 0.5351 - accuracy: 0.7384\n",
      "Epoch 180/200\n",
      "804/804 [==============================] - 0s 362us/step - loss: 0.5351 - accuracy: 0.7384\n",
      "Epoch 181/200\n",
      "804/804 [==============================] - 0s 363us/step - loss: 0.5349 - accuracy: 0.7378\n",
      "Epoch 182/200\n",
      "804/804 [==============================] - 0s 383us/step - loss: 0.5350 - accuracy: 0.7378\n",
      "Epoch 183/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5349 - accuracy: 0.7375\n",
      "Epoch 184/200\n",
      "804/804 [==============================] - 0s 376us/step - loss: 0.5353 - accuracy: 0.7380\n",
      "Epoch 185/200\n",
      "804/804 [==============================] - 0s 360us/step - loss: 0.5351 - accuracy: 0.7369\n",
      "Epoch 186/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5349 - accuracy: 0.7383\n",
      "Epoch 187/200\n",
      "804/804 [==============================] - 0s 382us/step - loss: 0.5355 - accuracy: 0.7387\n",
      "Epoch 188/200\n",
      "804/804 [==============================] - 0s 431us/step - loss: 0.5352 - accuracy: 0.7375\n",
      "Epoch 189/200\n",
      "804/804 [==============================] - 0s 423us/step - loss: 0.5346 - accuracy: 0.7386\n",
      "Epoch 190/200\n",
      "804/804 [==============================] - 0s 359us/step - loss: 0.5350 - accuracy: 0.7385\n",
      "Epoch 191/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5351 - accuracy: 0.7379\n",
      "Epoch 192/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5352 - accuracy: 0.7388\n",
      "Epoch 193/200\n",
      "804/804 [==============================] - 0s 358us/step - loss: 0.5348 - accuracy: 0.7389\n",
      "Epoch 194/200\n",
      "804/804 [==============================] - 0s 362us/step - loss: 0.5351 - accuracy: 0.7388\n",
      "Epoch 195/200\n",
      "804/804 [==============================] - 0s 370us/step - loss: 0.5351 - accuracy: 0.7386\n",
      "Epoch 196/200\n",
      "804/804 [==============================] - 0s 384us/step - loss: 0.5348 - accuracy: 0.7371\n",
      "Epoch 197/200\n",
      "804/804 [==============================] - 0s 356us/step - loss: 0.5348 - accuracy: 0.7384\n",
      "Epoch 198/200\n",
      "804/804 [==============================] - 0s 370us/step - loss: 0.5348 - accuracy: 0.7393\n",
      "Epoch 199/200\n",
      "804/804 [==============================] - 0s 355us/step - loss: 0.5350 - accuracy: 0.7382\n",
      "Epoch 200/200\n",
      "804/804 [==============================] - 0s 357us/step - loss: 0.5348 - accuracy: 0.7383\n"
     ]
    }
   ],
   "source": [
    "fit_nn4 = nn4.fit(X_train_scaled, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5597 - accuracy: 0.7278 - 250ms/epoch - 931us/step\n",
      "Loss: 0.5596529245376587, Accuracy: 0.7278134226799011\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn4.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1402b2f5a88>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df4 = pd.DataFrame(fit_nn4.history)\n",
    "\n",
    "# Increase the index by 1 to match the number of epochs\n",
    "history_df4.index += 1\n",
    "\n",
    "# Plot the loss\n",
    "history_df4.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Revision 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_68 (Dense)            (None, 4)                 200       \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225\n",
      "Trainable params: 225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn5 = tf.keras.models.Sequential()\n",
    "\n",
    "input_features = len(X_train_scaled[0])\n",
    "\n",
    "# Add our first Dense layer, including the input layer\n",
    "nn5.add(tf.keras.layers.Dense(units=4, activation=\"sigmoid\", input_dim=input_features))\n",
    "\n",
    "nn5.add(tf.keras.layers.Dense(units=4, activation='sigmoid'))\n",
    "\n",
    "# Add the output layer that uses a probability activation function\n",
    "nn5.add(tf.keras.layers.Dense(units=1, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# Check the structure of the Sequential model\n",
    "nn5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn5.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.7415 - accuracy: 0.5798\n",
      "Epoch 2/200\n",
      "804/804 [==============================] - 1s 968us/step - loss: 0.6054 - accuracy: 0.7178\n",
      "Epoch 3/200\n",
      "804/804 [==============================] - 1s 989us/step - loss: 0.5792 - accuracy: 0.7222\n",
      "Epoch 4/200\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5715 - accuracy: 0.7243\n",
      "Epoch 5/200\n",
      "804/804 [==============================] - 1s 983us/step - loss: 0.5670 - accuracy: 0.7243\n",
      "Epoch 6/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5633 - accuracy: 0.7268\n",
      "Epoch 7/200\n",
      "804/804 [==============================] - 1s 970us/step - loss: 0.5601 - accuracy: 0.7277\n",
      "Epoch 8/200\n",
      "804/804 [==============================] - 1s 989us/step - loss: 0.5576 - accuracy: 0.7283\n",
      "Epoch 9/200\n",
      "804/804 [==============================] - 1s 971us/step - loss: 0.5558 - accuracy: 0.7278\n",
      "Epoch 10/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5543 - accuracy: 0.7293\n",
      "Epoch 11/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5536 - accuracy: 0.7295\n",
      "Epoch 12/200\n",
      "804/804 [==============================] - 1s 994us/step - loss: 0.5528 - accuracy: 0.7296\n",
      "Epoch 13/200\n",
      "804/804 [==============================] - 1s 988us/step - loss: 0.5524 - accuracy: 0.7301\n",
      "Epoch 14/200\n",
      "804/804 [==============================] - 1s 964us/step - loss: 0.5515 - accuracy: 0.7297\n",
      "Epoch 15/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5515 - accuracy: 0.7295\n",
      "Epoch 16/200\n",
      "804/804 [==============================] - 1s 980us/step - loss: 0.5510 - accuracy: 0.7300\n",
      "Epoch 17/200\n",
      "804/804 [==============================] - 1s 973us/step - loss: 0.5504 - accuracy: 0.7299\n",
      "Epoch 18/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5504 - accuracy: 0.7306\n",
      "Epoch 19/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5504 - accuracy: 0.7306\n",
      "Epoch 20/200\n",
      "804/804 [==============================] - 1s 990us/step - loss: 0.5501 - accuracy: 0.7308\n",
      "Epoch 21/200\n",
      "804/804 [==============================] - 1s 978us/step - loss: 0.5500 - accuracy: 0.7304\n",
      "Epoch 22/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5518 - accuracy: 0.7308\n",
      "Epoch 23/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5497 - accuracy: 0.7314\n",
      "Epoch 24/200\n",
      "804/804 [==============================] - 1s 966us/step - loss: 0.5497 - accuracy: 0.7300\n",
      "Epoch 25/200\n",
      "804/804 [==============================] - 1s 994us/step - loss: 0.5496 - accuracy: 0.7304\n",
      "Epoch 26/200\n",
      "804/804 [==============================] - 1s 978us/step - loss: 0.5489 - accuracy: 0.7309\n",
      "Epoch 27/200\n",
      "804/804 [==============================] - 1s 957us/step - loss: 0.5490 - accuracy: 0.7303\n",
      "Epoch 28/200\n",
      "804/804 [==============================] - 1s 989us/step - loss: 0.5490 - accuracy: 0.7300\n",
      "Epoch 29/200\n",
      "804/804 [==============================] - 1s 961us/step - loss: 0.5507 - accuracy: 0.7297\n",
      "Epoch 30/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5484 - accuracy: 0.7307\n",
      "Epoch 31/200\n",
      "804/804 [==============================] - 1s 997us/step - loss: 0.5484 - accuracy: 0.7308\n",
      "Epoch 32/200\n",
      "804/804 [==============================] - 1s 957us/step - loss: 0.5484 - accuracy: 0.7303\n",
      "Epoch 33/200\n",
      "804/804 [==============================] - 1s 984us/step - loss: 0.5482 - accuracy: 0.7308\n",
      "Epoch 34/200\n",
      "804/804 [==============================] - 1s 973us/step - loss: 0.5484 - accuracy: 0.7301\n",
      "Epoch 35/200\n",
      "804/804 [==============================] - 1s 992us/step - loss: 0.5483 - accuracy: 0.7299\n",
      "Epoch 36/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5482 - accuracy: 0.7313\n",
      "Epoch 37/200\n",
      "804/804 [==============================] - 1s 967us/step - loss: 0.5484 - accuracy: 0.7299\n",
      "Epoch 38/200\n",
      "804/804 [==============================] - 1s 991us/step - loss: 0.5483 - accuracy: 0.7296\n",
      "Epoch 39/200\n",
      "804/804 [==============================] - 1s 966us/step - loss: 0.5483 - accuracy: 0.7306\n",
      "Epoch 40/200\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5478 - accuracy: 0.7301\n",
      "Epoch 41/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5486 - accuracy: 0.7306\n",
      "Epoch 42/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7305\n",
      "Epoch 43/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5476 - accuracy: 0.7306\n",
      "Epoch 44/200\n",
      "804/804 [==============================] - 1s 961us/step - loss: 0.5475 - accuracy: 0.7311\n",
      "Epoch 45/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5479 - accuracy: 0.7311\n",
      "Epoch 46/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5473 - accuracy: 0.7296\n",
      "Epoch 47/200\n",
      "804/804 [==============================] - 1s 978us/step - loss: 0.5473 - accuracy: 0.7295\n",
      "Epoch 48/200\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5474 - accuracy: 0.7302\n",
      "Epoch 49/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5473 - accuracy: 0.7308\n",
      "Epoch 50/200\n",
      "804/804 [==============================] - 1s 986us/step - loss: 0.5472 - accuracy: 0.7303\n",
      "Epoch 51/200\n",
      "804/804 [==============================] - 1s 973us/step - loss: 0.5472 - accuracy: 0.7309\n",
      "Epoch 52/200\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5470 - accuracy: 0.7309\n",
      "Epoch 53/200\n",
      "804/804 [==============================] - 1s 989us/step - loss: 0.5474 - accuracy: 0.7301\n",
      "Epoch 54/200\n",
      "804/804 [==============================] - 1s 978us/step - loss: 0.5468 - accuracy: 0.7314\n",
      "Epoch 55/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5469 - accuracy: 0.7294\n",
      "Epoch 56/200\n",
      "804/804 [==============================] - 1s 991us/step - loss: 0.5488 - accuracy: 0.7308\n",
      "Epoch 57/200\n",
      "804/804 [==============================] - 1s 985us/step - loss: 0.5467 - accuracy: 0.7305\n",
      "Epoch 58/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5482 - accuracy: 0.7303\n",
      "Epoch 59/200\n",
      "804/804 [==============================] - 1s 974us/step - loss: 0.5475 - accuracy: 0.7312\n",
      "Epoch 60/200\n",
      "804/804 [==============================] - 1s 973us/step - loss: 0.5471 - accuracy: 0.7311\n",
      "Epoch 61/200\n",
      "804/804 [==============================] - 1s 992us/step - loss: 0.5466 - accuracy: 0.7307\n",
      "Epoch 62/200\n",
      "804/804 [==============================] - 1s 986us/step - loss: 0.5467 - accuracy: 0.7305\n",
      "Epoch 63/200\n",
      "804/804 [==============================] - 1s 992us/step - loss: 0.5465 - accuracy: 0.7305\n",
      "Epoch 64/200\n",
      "804/804 [==============================] - 1s 980us/step - loss: 0.5466 - accuracy: 0.7310\n",
      "Epoch 65/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5467 - accuracy: 0.7306\n",
      "Epoch 66/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5464 - accuracy: 0.7306\n",
      "Epoch 67/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5467 - accuracy: 0.7309\n",
      "Epoch 68/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5470 - accuracy: 0.7305\n",
      "Epoch 69/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5462 - accuracy: 0.7304\n",
      "Epoch 70/200\n",
      "804/804 [==============================] - 1s 989us/step - loss: 0.5467 - accuracy: 0.7317\n",
      "Epoch 71/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5462 - accuracy: 0.7303\n",
      "Epoch 72/200\n",
      "804/804 [==============================] - 1s 983us/step - loss: 0.5467 - accuracy: 0.7310\n",
      "Epoch 73/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5461 - accuracy: 0.7313\n",
      "Epoch 74/200\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5468 - accuracy: 0.7303\n",
      "Epoch 75/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5461 - accuracy: 0.7305\n",
      "Epoch 76/200\n",
      "804/804 [==============================] - 1s 988us/step - loss: 0.5461 - accuracy: 0.7315\n",
      "Epoch 77/200\n",
      "804/804 [==============================] - 1s 971us/step - loss: 0.5466 - accuracy: 0.7311\n",
      "Epoch 78/200\n",
      "804/804 [==============================] - 1s 988us/step - loss: 0.5472 - accuracy: 0.7313\n",
      "Epoch 79/200\n",
      "804/804 [==============================] - 1s 990us/step - loss: 0.5477 - accuracy: 0.7312\n",
      "Epoch 80/200\n",
      "804/804 [==============================] - 1s 983us/step - loss: 0.5461 - accuracy: 0.7309\n",
      "Epoch 81/200\n",
      "804/804 [==============================] - 1s 976us/step - loss: 0.5463 - accuracy: 0.7307\n",
      "Epoch 82/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7303\n",
      "Epoch 83/200\n",
      "804/804 [==============================] - 1s 984us/step - loss: 0.5472 - accuracy: 0.7305\n",
      "Epoch 84/200\n",
      "804/804 [==============================] - 1s 963us/step - loss: 0.5466 - accuracy: 0.7299\n",
      "Epoch 85/200\n",
      "804/804 [==============================] - 1s 978us/step - loss: 0.5459 - accuracy: 0.7314\n",
      "Epoch 86/200\n",
      "804/804 [==============================] - 1s 981us/step - loss: 0.5457 - accuracy: 0.7302\n",
      "Epoch 87/200\n",
      "804/804 [==============================] - 1s 975us/step - loss: 0.5457 - accuracy: 0.7318\n",
      "Epoch 88/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7310\n",
      "Epoch 89/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5465 - accuracy: 0.7308\n",
      "Epoch 90/200\n",
      "804/804 [==============================] - 1s 990us/step - loss: 0.5460 - accuracy: 0.7313\n",
      "Epoch 91/200\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5460 - accuracy: 0.7312\n",
      "Epoch 92/200\n",
      "804/804 [==============================] - 1s 973us/step - loss: 0.5455 - accuracy: 0.7316\n",
      "Epoch 93/200\n",
      "804/804 [==============================] - 1s 999us/step - loss: 0.5460 - accuracy: 0.7308\n",
      "Epoch 94/200\n",
      "804/804 [==============================] - 1s 969us/step - loss: 0.5457 - accuracy: 0.7308\n",
      "Epoch 95/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7312\n",
      "Epoch 96/200\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5460 - accuracy: 0.7303\n",
      "Epoch 97/200\n",
      "804/804 [==============================] - 1s 974us/step - loss: 0.5458 - accuracy: 0.7306\n",
      "Epoch 98/200\n",
      "804/804 [==============================] - 1s 999us/step - loss: 0.5459 - accuracy: 0.7312\n",
      "Epoch 99/200\n",
      "804/804 [==============================] - 1s 973us/step - loss: 0.5456 - accuracy: 0.7306\n",
      "Epoch 100/200\n",
      "804/804 [==============================] - 1s 993us/step - loss: 0.5455 - accuracy: 0.7314\n",
      "Epoch 101/200\n",
      "804/804 [==============================] - 1s 981us/step - loss: 0.5479 - accuracy: 0.7308\n",
      "Epoch 102/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7298\n",
      "Epoch 103/200\n",
      "804/804 [==============================] - 1s 990us/step - loss: 0.5454 - accuracy: 0.7299\n",
      "Epoch 104/200\n",
      "804/804 [==============================] - 1s 962us/step - loss: 0.5456 - accuracy: 0.7310\n",
      "Epoch 105/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5455 - accuracy: 0.7304\n",
      "Epoch 106/200\n",
      "804/804 [==============================] - 1s 983us/step - loss: 0.5456 - accuracy: 0.7313\n",
      "Epoch 107/200\n",
      "804/804 [==============================] - 1s 973us/step - loss: 0.5460 - accuracy: 0.7312\n",
      "Epoch 108/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5461 - accuracy: 0.7310\n",
      "Epoch 109/200\n",
      "804/804 [==============================] - 1s 967us/step - loss: 0.5458 - accuracy: 0.7309\n",
      "Epoch 110/200\n",
      "804/804 [==============================] - 1s 984us/step - loss: 0.5457 - accuracy: 0.7302\n",
      "Epoch 111/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7318\n",
      "Epoch 112/200\n",
      "804/804 [==============================] - 1s 974us/step - loss: 0.5477 - accuracy: 0.7297\n",
      "Epoch 113/200\n",
      "804/804 [==============================] - 1s 987us/step - loss: 0.5456 - accuracy: 0.7306\n",
      "Epoch 114/200\n",
      "804/804 [==============================] - 1s 989us/step - loss: 0.5457 - accuracy: 0.7310\n",
      "Epoch 115/200\n",
      "804/804 [==============================] - 1s 974us/step - loss: 0.5463 - accuracy: 0.7315\n",
      "Epoch 116/200\n",
      "804/804 [==============================] - 1s 993us/step - loss: 0.5455 - accuracy: 0.7315\n",
      "Epoch 117/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7307\n",
      "Epoch 118/200\n",
      "804/804 [==============================] - 1s 993us/step - loss: 0.5462 - accuracy: 0.7309\n",
      "Epoch 119/200\n",
      "804/804 [==============================] - 1s 968us/step - loss: 0.5451 - accuracy: 0.7316\n",
      "Epoch 120/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5454 - accuracy: 0.7309\n",
      "Epoch 121/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5461 - accuracy: 0.7303\n",
      "Epoch 122/200\n",
      "804/804 [==============================] - 1s 971us/step - loss: 0.5453 - accuracy: 0.7312\n",
      "Epoch 123/200\n",
      "804/804 [==============================] - 1s 996us/step - loss: 0.5453 - accuracy: 0.7312\n",
      "Epoch 124/200\n",
      "804/804 [==============================] - 1s 988us/step - loss: 0.5459 - accuracy: 0.7308\n",
      "Epoch 125/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5460 - accuracy: 0.7318\n",
      "Epoch 126/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5453 - accuracy: 0.7316\n",
      "Epoch 127/200\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5450 - accuracy: 0.7319\n",
      "Epoch 128/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5453 - accuracy: 0.7311\n",
      "Epoch 129/200\n",
      "804/804 [==============================] - 1s 962us/step - loss: 0.5457 - accuracy: 0.7300\n",
      "Epoch 130/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5487 - accuracy: 0.7294\n",
      "Epoch 131/200\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5453 - accuracy: 0.7307\n",
      "Epoch 132/200\n",
      "804/804 [==============================] - 1s 984us/step - loss: 0.5451 - accuracy: 0.7313\n",
      "Epoch 133/200\n",
      "804/804 [==============================] - 1s 970us/step - loss: 0.5452 - accuracy: 0.7315\n",
      "Epoch 134/200\n",
      "804/804 [==============================] - 1s 975us/step - loss: 0.5451 - accuracy: 0.7314\n",
      "Epoch 135/200\n",
      "804/804 [==============================] - 1s 992us/step - loss: 0.5464 - accuracy: 0.7313\n",
      "Epoch 136/200\n",
      "804/804 [==============================] - 1s 980us/step - loss: 0.5451 - accuracy: 0.7312\n",
      "Epoch 137/200\n",
      "804/804 [==============================] - 1s 964us/step - loss: 0.5449 - accuracy: 0.7311\n",
      "Epoch 138/200\n",
      "804/804 [==============================] - 1s 993us/step - loss: 0.5449 - accuracy: 0.7312\n",
      "Epoch 139/200\n",
      "804/804 [==============================] - 1s 964us/step - loss: 0.5456 - accuracy: 0.7303\n",
      "Epoch 140/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7309\n",
      "Epoch 141/200\n",
      "804/804 [==============================] - 1s 995us/step - loss: 0.5462 - accuracy: 0.7311\n",
      "Epoch 142/200\n",
      "804/804 [==============================] - 1s 953us/step - loss: 0.5452 - accuracy: 0.7303\n",
      "Epoch 143/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7307\n",
      "Epoch 144/200\n",
      "804/804 [==============================] - 1s 992us/step - loss: 0.5448 - accuracy: 0.7313\n",
      "Epoch 145/200\n",
      "804/804 [==============================] - 1s 970us/step - loss: 0.5448 - accuracy: 0.7315\n",
      "Epoch 146/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5450 - accuracy: 0.7296\n",
      "Epoch 147/200\n",
      "804/804 [==============================] - 1s 964us/step - loss: 0.5456 - accuracy: 0.7301\n",
      "Epoch 148/200\n",
      "804/804 [==============================] - 1s 999us/step - loss: 0.5448 - accuracy: 0.7314\n",
      "Epoch 149/200\n",
      "804/804 [==============================] - 1s 989us/step - loss: 0.5448 - accuracy: 0.7307\n",
      "Epoch 150/200\n",
      "804/804 [==============================] - 1s 967us/step - loss: 0.5448 - accuracy: 0.7309\n",
      "Epoch 151/200\n",
      "804/804 [==============================] - 1s 974us/step - loss: 0.5448 - accuracy: 0.7317\n",
      "Epoch 152/200\n",
      "804/804 [==============================] - 1s 992us/step - loss: 0.5450 - accuracy: 0.7306\n",
      "Epoch 153/200\n",
      "804/804 [==============================] - 1s 977us/step - loss: 0.5447 - accuracy: 0.7308\n",
      "Epoch 154/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5455 - accuracy: 0.7306\n",
      "Epoch 155/200\n",
      "804/804 [==============================] - 1s 970us/step - loss: 0.5447 - accuracy: 0.7311\n",
      "Epoch 156/200\n",
      "804/804 [==============================] - 1s 990us/step - loss: 0.5454 - accuracy: 0.7301\n",
      "Epoch 157/200\n",
      "804/804 [==============================] - 1s 962us/step - loss: 0.5452 - accuracy: 0.7304\n",
      "Epoch 158/200\n",
      "804/804 [==============================] - 1s 997us/step - loss: 0.5446 - accuracy: 0.7310\n",
      "Epoch 159/200\n",
      "804/804 [==============================] - 1s 971us/step - loss: 0.5454 - accuracy: 0.7305\n",
      "Epoch 160/200\n",
      "804/804 [==============================] - 1s 977us/step - loss: 0.5456 - accuracy: 0.7308\n",
      "Epoch 161/200\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5449 - accuracy: 0.7308\n",
      "Epoch 162/200\n",
      "804/804 [==============================] - 1s 962us/step - loss: 0.5453 - accuracy: 0.7312\n",
      "Epoch 163/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5454 - accuracy: 0.7312\n",
      "Epoch 164/200\n",
      "804/804 [==============================] - 1s 959us/step - loss: 0.5447 - accuracy: 0.7310\n",
      "Epoch 165/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5444 - accuracy: 0.7307\n",
      "Epoch 166/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7310\n",
      "Epoch 167/200\n",
      "804/804 [==============================] - 1s 986us/step - loss: 0.5444 - accuracy: 0.7308\n",
      "Epoch 168/200\n",
      "804/804 [==============================] - 1s 975us/step - loss: 0.5451 - accuracy: 0.7307\n",
      "Epoch 169/200\n",
      "804/804 [==============================] - 1s 978us/step - loss: 0.5448 - accuracy: 0.7308\n",
      "Epoch 170/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5446 - accuracy: 0.7303\n",
      "Epoch 171/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7314\n",
      "Epoch 172/200\n",
      "804/804 [==============================] - 1s 967us/step - loss: 0.5446 - accuracy: 0.7310\n",
      "Epoch 173/200\n",
      "804/804 [==============================] - 1s 966us/step - loss: 0.5459 - accuracy: 0.7315\n",
      "Epoch 174/200\n",
      "804/804 [==============================] - 1s 977us/step - loss: 0.5447 - accuracy: 0.7307\n",
      "Epoch 175/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7301\n",
      "Epoch 176/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5447 - accuracy: 0.7304\n",
      "Epoch 177/200\n",
      "804/804 [==============================] - 1s 959us/step - loss: 0.5444 - accuracy: 0.7311\n",
      "Epoch 178/200\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5451 - accuracy: 0.7312\n",
      "Epoch 179/200\n",
      "804/804 [==============================] - 1s 997us/step - loss: 0.5450 - accuracy: 0.7308\n",
      "Epoch 180/200\n",
      "804/804 [==============================] - 1s 989us/step - loss: 0.5446 - accuracy: 0.7309\n",
      "Epoch 181/200\n",
      "804/804 [==============================] - 1s 992us/step - loss: 0.5447 - accuracy: 0.7308\n",
      "Epoch 182/200\n",
      "804/804 [==============================] - 1s 963us/step - loss: 0.5449 - accuracy: 0.7310\n",
      "Epoch 183/200\n",
      "804/804 [==============================] - 1s 991us/step - loss: 0.5452 - accuracy: 0.7312\n",
      "Epoch 184/200\n",
      "804/804 [==============================] - 1s 965us/step - loss: 0.5448 - accuracy: 0.7311\n",
      "Epoch 185/200\n",
      "804/804 [==============================] - 1s 965us/step - loss: 0.5448 - accuracy: 0.7314\n",
      "Epoch 186/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5495 - accuracy: 0.7303\n",
      "Epoch 187/200\n",
      "804/804 [==============================] - 1s 985us/step - loss: 0.5475 - accuracy: 0.7310\n",
      "Epoch 188/200\n",
      "804/804 [==============================] - 1s 962us/step - loss: 0.5464 - accuracy: 0.7308\n",
      "Epoch 189/200\n",
      "804/804 [==============================] - 1s 973us/step - loss: 0.5461 - accuracy: 0.7317\n",
      "Epoch 190/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5454 - accuracy: 0.7314\n",
      "Epoch 191/200\n",
      "804/804 [==============================] - 1s 994us/step - loss: 0.5452 - accuracy: 0.7314\n",
      "Epoch 192/200\n",
      "804/804 [==============================] - 1s 976us/step - loss: 0.5448 - accuracy: 0.7313\n",
      "Epoch 193/200\n",
      "804/804 [==============================] - 1s 981us/step - loss: 0.5445 - accuracy: 0.7319\n",
      "Epoch 194/200\n",
      "804/804 [==============================] - 1s 994us/step - loss: 0.5446 - accuracy: 0.7309\n",
      "Epoch 195/200\n",
      "804/804 [==============================] - 1s 965us/step - loss: 0.5441 - accuracy: 0.7327\n",
      "Epoch 196/200\n",
      "804/804 [==============================] - 1s 991us/step - loss: 0.5442 - accuracy: 0.7315\n",
      "Epoch 197/200\n",
      "804/804 [==============================] - 1s 983us/step - loss: 0.5442 - accuracy: 0.7316\n",
      "Epoch 198/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7309\n",
      "Epoch 199/200\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5443 - accuracy: 0.7316\n",
      "Epoch 200/200\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5444 - accuracy: 0.7312\n"
     ]
    }
   ],
   "source": [
    "fit_nn5 = nn5.fit(X_train_scaled, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5552 - accuracy: 0.7292 - 291ms/epoch - 1ms/step\n",
      "Loss: 0.5552169680595398, Accuracy: 0.7292128205299377\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn5.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1402b9fd7c8>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df5 = pd.DataFrame(fit_nn5.history)\n",
    "\n",
    "# Increase the index by 1 to match the number of epochs\n",
    "history_df5.index += 1\n",
    "\n",
    "# Plot the loss\n",
    "history_df5.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save and export your results to an HDF5 file. Name the file `AlphabetSoupCharity_Optimization.h5`.\n",
    "\n",
    "model_json = nn2.to_json()\n",
    "with open(\"AlphabetSoupCharity_Optimization\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "nn2.save_weights(\"AlphabetSoupCharity_Optimization.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_107 (Dense)           (None, 49)                2450      \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 8)                 400       \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,931\n",
      "Trainable params: 2,931\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn6 = tf.keras.models.Sequential()\n",
    "\n",
    "input_features = len(X_train_scaled[0])\n",
    "\n",
    "# Add our first Dense layer, including the input layer\n",
    "nn6.add(tf.keras.layers.Dense(units=49, activation=\"relu\", input_dim=input_features))\n",
    "\n",
    "nn6.add(tf.keras.layers.Dense(units=8, activation='relu'))\n",
    "\n",
    "nn6.add(tf.keras.layers.Dense(units=8, activation='relu'))\n",
    "\n",
    "# Add the output layer that uses a probability activation function\n",
    "nn6.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Check the structure of the Sequential model\n",
    "nn6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn6.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"], steps_per_execution= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5808 - accuracy: 0.7132\n",
      "Epoch 2/250\n",
      "804/804 [==============================] - 0s 314us/step - loss: 0.5522 - accuracy: 0.7301\n",
      "Epoch 3/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5485 - accuracy: 0.7323\n",
      "Epoch 4/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5464 - accuracy: 0.7314\n",
      "Epoch 5/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5446 - accuracy: 0.7338\n",
      "Epoch 6/250\n",
      "804/804 [==============================] - 0s 305us/step - loss: 0.5431 - accuracy: 0.7332\n",
      "Epoch 7/250\n",
      "804/804 [==============================] - 0s 299us/step - loss: 0.5422 - accuracy: 0.7357\n",
      "Epoch 8/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5414 - accuracy: 0.7352\n",
      "Epoch 9/250\n",
      "804/804 [==============================] - 0s 299us/step - loss: 0.5408 - accuracy: 0.7362\n",
      "Epoch 10/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5399 - accuracy: 0.7363\n",
      "Epoch 11/250\n",
      "804/804 [==============================] - 0s 319us/step - loss: 0.5392 - accuracy: 0.7364\n",
      "Epoch 12/250\n",
      "804/804 [==============================] - 0s 299us/step - loss: 0.5394 - accuracy: 0.7364\n",
      "Epoch 13/250\n",
      "804/804 [==============================] - 0s 339us/step - loss: 0.5385 - accuracy: 0.7371\n",
      "Epoch 14/250\n",
      "804/804 [==============================] - 0s 335us/step - loss: 0.5384 - accuracy: 0.7370\n",
      "Epoch 15/250\n",
      "804/804 [==============================] - 0s 330us/step - loss: 0.5378 - accuracy: 0.7381\n",
      "Epoch 16/250\n",
      "804/804 [==============================] - 0s 311us/step - loss: 0.5375 - accuracy: 0.7382\n",
      "Epoch 17/250\n",
      "804/804 [==============================] - 0s 320us/step - loss: 0.5367 - accuracy: 0.7388\n",
      "Epoch 18/250\n",
      "804/804 [==============================] - 0s 304us/step - loss: 0.5362 - accuracy: 0.7378\n",
      "Epoch 19/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5363 - accuracy: 0.7388\n",
      "Epoch 20/250\n",
      "804/804 [==============================] - 0s 289us/step - loss: 0.5353 - accuracy: 0.7371\n",
      "Epoch 21/250\n",
      "804/804 [==============================] - 0s 296us/step - loss: 0.5356 - accuracy: 0.7390\n",
      "Epoch 22/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5354 - accuracy: 0.7385\n",
      "Epoch 23/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5348 - accuracy: 0.7392\n",
      "Epoch 24/250\n",
      "804/804 [==============================] - 0s 296us/step - loss: 0.5345 - accuracy: 0.7403\n",
      "Epoch 25/250\n",
      "804/804 [==============================] - 0s 302us/step - loss: 0.5345 - accuracy: 0.7399\n",
      "Epoch 26/250\n",
      "804/804 [==============================] - 0s 302us/step - loss: 0.5340 - accuracy: 0.7390\n",
      "Epoch 27/250\n",
      "804/804 [==============================] - 0s 314us/step - loss: 0.5339 - accuracy: 0.7405\n",
      "Epoch 28/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5338 - accuracy: 0.7393\n",
      "Epoch 29/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5331 - accuracy: 0.7399\n",
      "Epoch 30/250\n",
      "804/804 [==============================] - 0s 304us/step - loss: 0.5329 - accuracy: 0.7391\n",
      "Epoch 31/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5329 - accuracy: 0.7410\n",
      "Epoch 32/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5322 - accuracy: 0.7409\n",
      "Epoch 33/250\n",
      "804/804 [==============================] - 0s 291us/step - loss: 0.5322 - accuracy: 0.7401\n",
      "Epoch 34/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5327 - accuracy: 0.7395\n",
      "Epoch 35/250\n",
      "804/804 [==============================] - 0s 299us/step - loss: 0.5319 - accuracy: 0.7403\n",
      "Epoch 36/250\n",
      "804/804 [==============================] - 0s 309us/step - loss: 0.5314 - accuracy: 0.7409\n",
      "Epoch 37/250\n",
      "804/804 [==============================] - 0s 290us/step - loss: 0.5321 - accuracy: 0.7387\n",
      "Epoch 38/250\n",
      "804/804 [==============================] - 0s 302us/step - loss: 0.5311 - accuracy: 0.7414\n",
      "Epoch 39/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5307 - accuracy: 0.7416\n",
      "Epoch 40/250\n",
      "804/804 [==============================] - 0s 304us/step - loss: 0.5310 - accuracy: 0.7405\n",
      "Epoch 41/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5309 - accuracy: 0.7400\n",
      "Epoch 42/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5313 - accuracy: 0.7410\n",
      "Epoch 43/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5305 - accuracy: 0.7414\n",
      "Epoch 44/250\n",
      "804/804 [==============================] - 0s 304us/step - loss: 0.5308 - accuracy: 0.7411\n",
      "Epoch 45/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5298 - accuracy: 0.7414\n",
      "Epoch 46/250\n",
      "804/804 [==============================] - 0s 303us/step - loss: 0.5296 - accuracy: 0.7412\n",
      "Epoch 47/250\n",
      "804/804 [==============================] - 0s 292us/step - loss: 0.5297 - accuracy: 0.7416\n",
      "Epoch 48/250\n",
      "804/804 [==============================] - 0s 297us/step - loss: 0.5296 - accuracy: 0.7409\n",
      "Epoch 49/250\n",
      "804/804 [==============================] - 0s 290us/step - loss: 0.5301 - accuracy: 0.7420\n",
      "Epoch 50/250\n",
      "804/804 [==============================] - 0s 292us/step - loss: 0.5295 - accuracy: 0.7417\n",
      "Epoch 51/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5290 - accuracy: 0.7416\n",
      "Epoch 52/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5293 - accuracy: 0.7427\n",
      "Epoch 53/250\n",
      "804/804 [==============================] - 0s 305us/step - loss: 0.5286 - accuracy: 0.7417\n",
      "Epoch 54/250\n",
      "804/804 [==============================] - 0s 290us/step - loss: 0.5292 - accuracy: 0.7415\n",
      "Epoch 55/250\n",
      "804/804 [==============================] - 0s 296us/step - loss: 0.5289 - accuracy: 0.7420\n",
      "Epoch 56/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5292 - accuracy: 0.7414\n",
      "Epoch 57/250\n",
      "804/804 [==============================] - 0s 288us/step - loss: 0.5286 - accuracy: 0.7424\n",
      "Epoch 58/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5287 - accuracy: 0.7423\n",
      "Epoch 59/250\n",
      "804/804 [==============================] - 0s 313us/step - loss: 0.5286 - accuracy: 0.7419\n",
      "Epoch 60/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5282 - accuracy: 0.7428\n",
      "Epoch 61/250\n",
      "804/804 [==============================] - 0s 293us/step - loss: 0.5285 - accuracy: 0.7418\n",
      "Epoch 62/250\n",
      "804/804 [==============================] - 0s 284us/step - loss: 0.5280 - accuracy: 0.7426\n",
      "Epoch 63/250\n",
      "804/804 [==============================] - 0s 290us/step - loss: 0.5282 - accuracy: 0.7425\n",
      "Epoch 64/250\n",
      "804/804 [==============================] - 0s 293us/step - loss: 0.5279 - accuracy: 0.7425\n",
      "Epoch 65/250\n",
      "804/804 [==============================] - 0s 305us/step - loss: 0.5272 - accuracy: 0.7429\n",
      "Epoch 66/250\n",
      "804/804 [==============================] - 0s 305us/step - loss: 0.5275 - accuracy: 0.7420\n",
      "Epoch 67/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5278 - accuracy: 0.7425\n",
      "Epoch 68/250\n",
      "804/804 [==============================] - 0s 309us/step - loss: 0.5275 - accuracy: 0.7423\n",
      "Epoch 69/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5266 - accuracy: 0.7420\n",
      "Epoch 70/250\n",
      "804/804 [==============================] - 0s 296us/step - loss: 0.5272 - accuracy: 0.7421\n",
      "Epoch 71/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5268 - accuracy: 0.7436\n",
      "Epoch 72/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5271 - accuracy: 0.7434\n",
      "Epoch 73/250\n",
      "804/804 [==============================] - 0s 306us/step - loss: 0.5269 - accuracy: 0.7424\n",
      "Epoch 74/250\n",
      "804/804 [==============================] - 0s 300us/step - loss: 0.5267 - accuracy: 0.7431\n",
      "Epoch 75/250\n",
      "804/804 [==============================] - 0s 306us/step - loss: 0.5271 - accuracy: 0.7432\n",
      "Epoch 76/250\n",
      "804/804 [==============================] - 0s 303us/step - loss: 0.5264 - accuracy: 0.7427\n",
      "Epoch 77/250\n",
      "804/804 [==============================] - 0s 302us/step - loss: 0.5267 - accuracy: 0.7435\n",
      "Epoch 78/250\n",
      "804/804 [==============================] - 0s 291us/step - loss: 0.5265 - accuracy: 0.7425\n",
      "Epoch 79/250\n",
      "804/804 [==============================] - 0s 290us/step - loss: 0.5266 - accuracy: 0.7432\n",
      "Epoch 80/250\n",
      "804/804 [==============================] - 0s 291us/step - loss: 0.5266 - accuracy: 0.7425\n",
      "Epoch 81/250\n",
      "804/804 [==============================] - 0s 304us/step - loss: 0.5262 - accuracy: 0.7440\n",
      "Epoch 82/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5258 - accuracy: 0.7429\n",
      "Epoch 83/250\n",
      "804/804 [==============================] - 0s 304us/step - loss: 0.5264 - accuracy: 0.7428\n",
      "Epoch 84/250\n",
      "804/804 [==============================] - 0s 303us/step - loss: 0.5262 - accuracy: 0.7429\n",
      "Epoch 85/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5263 - accuracy: 0.7427\n",
      "Epoch 86/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5257 - accuracy: 0.7437\n",
      "Epoch 87/250\n",
      "804/804 [==============================] - 0s 297us/step - loss: 0.5257 - accuracy: 0.7431\n",
      "Epoch 88/250\n",
      "804/804 [==============================] - 0s 292us/step - loss: 0.5258 - accuracy: 0.7439\n",
      "Epoch 89/250\n",
      "804/804 [==============================] - 0s 293us/step - loss: 0.5252 - accuracy: 0.7441\n",
      "Epoch 90/250\n",
      "804/804 [==============================] - 0s 305us/step - loss: 0.5253 - accuracy: 0.7444\n",
      "Epoch 91/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5257 - accuracy: 0.7433\n",
      "Epoch 92/250\n",
      "804/804 [==============================] - 0s 312us/step - loss: 0.5253 - accuracy: 0.7438\n",
      "Epoch 93/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5254 - accuracy: 0.7434\n",
      "Epoch 94/250\n",
      "804/804 [==============================] - 0s 315us/step - loss: 0.5250 - accuracy: 0.7448\n",
      "Epoch 95/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5252 - accuracy: 0.7435\n",
      "Epoch 96/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5247 - accuracy: 0.7449\n",
      "Epoch 97/250\n",
      "804/804 [==============================] - 0s 297us/step - loss: 0.5251 - accuracy: 0.7435\n",
      "Epoch 98/250\n",
      "804/804 [==============================] - 0s 293us/step - loss: 0.5253 - accuracy: 0.7446\n",
      "Epoch 99/250\n",
      "804/804 [==============================] - 0s 299us/step - loss: 0.5245 - accuracy: 0.7440\n",
      "Epoch 100/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5242 - accuracy: 0.7444\n",
      "Epoch 101/250\n",
      "804/804 [==============================] - 0s 302us/step - loss: 0.5245 - accuracy: 0.7443\n",
      "Epoch 102/250\n",
      "804/804 [==============================] - 0s 297us/step - loss: 0.5247 - accuracy: 0.7441\n",
      "Epoch 103/250\n",
      "804/804 [==============================] - 0s 296us/step - loss: 0.5241 - accuracy: 0.7435\n",
      "Epoch 104/250\n",
      "804/804 [==============================] - 0s 296us/step - loss: 0.5248 - accuracy: 0.7442\n",
      "Epoch 105/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5247 - accuracy: 0.7433\n",
      "Epoch 106/250\n",
      "804/804 [==============================] - 0s 300us/step - loss: 0.5239 - accuracy: 0.7450\n",
      "Epoch 107/250\n",
      "804/804 [==============================] - 0s 316us/step - loss: 0.5241 - accuracy: 0.7442\n",
      "Epoch 108/250\n",
      "804/804 [==============================] - 0s 302us/step - loss: 0.5240 - accuracy: 0.7451\n",
      "Epoch 109/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5241 - accuracy: 0.7440\n",
      "Epoch 110/250\n",
      "804/804 [==============================] - 0s 315us/step - loss: 0.5240 - accuracy: 0.7442\n",
      "Epoch 111/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5241 - accuracy: 0.7457\n",
      "Epoch 112/250\n",
      "804/804 [==============================] - 0s 299us/step - loss: 0.5235 - accuracy: 0.7452\n",
      "Epoch 113/250\n",
      "804/804 [==============================] - 0s 296us/step - loss: 0.5239 - accuracy: 0.7439\n",
      "Epoch 114/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5236 - accuracy: 0.7452\n",
      "Epoch 115/250\n",
      "804/804 [==============================] - 0s 299us/step - loss: 0.5234 - accuracy: 0.7452\n",
      "Epoch 116/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5234 - accuracy: 0.7443\n",
      "Epoch 117/250\n",
      "804/804 [==============================] - 0s 306us/step - loss: 0.5236 - accuracy: 0.7458\n",
      "Epoch 118/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5233 - accuracy: 0.7438\n",
      "Epoch 119/250\n",
      "804/804 [==============================] - 0s 296us/step - loss: 0.5233 - accuracy: 0.7453\n",
      "Epoch 120/250\n",
      "804/804 [==============================] - 0s 282us/step - loss: 0.5235 - accuracy: 0.7451\n",
      "Epoch 121/250\n",
      "804/804 [==============================] - 0s 296us/step - loss: 0.5231 - accuracy: 0.7447\n",
      "Epoch 122/250\n",
      "804/804 [==============================] - 0s 297us/step - loss: 0.5237 - accuracy: 0.7453\n",
      "Epoch 123/250\n",
      "804/804 [==============================] - 0s 315us/step - loss: 0.5234 - accuracy: 0.7453\n",
      "Epoch 124/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5229 - accuracy: 0.7455\n",
      "Epoch 125/250\n",
      "804/804 [==============================] - 0s 317us/step - loss: 0.5233 - accuracy: 0.7448\n",
      "Epoch 126/250\n",
      "804/804 [==============================] - 0s 296us/step - loss: 0.5229 - accuracy: 0.7451\n",
      "Epoch 127/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5231 - accuracy: 0.7454\n",
      "Epoch 128/250\n",
      "804/804 [==============================] - 0s 293us/step - loss: 0.5228 - accuracy: 0.7459\n",
      "Epoch 129/250\n",
      "804/804 [==============================] - 0s 297us/step - loss: 0.5227 - accuracy: 0.7453\n",
      "Epoch 130/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5230 - accuracy: 0.7458\n",
      "Epoch 131/250\n",
      "804/804 [==============================] - 0s 299us/step - loss: 0.5227 - accuracy: 0.7450\n",
      "Epoch 132/250\n",
      "804/804 [==============================] - 0s 302us/step - loss: 0.5228 - accuracy: 0.7449\n",
      "Epoch 133/250\n",
      "804/804 [==============================] - 0s 306us/step - loss: 0.5228 - accuracy: 0.7455\n",
      "Epoch 134/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5230 - accuracy: 0.7457\n",
      "Epoch 135/250\n",
      "804/804 [==============================] - 0s 286us/step - loss: 0.5224 - accuracy: 0.7460\n",
      "Epoch 136/250\n",
      "804/804 [==============================] - 0s 283us/step - loss: 0.5229 - accuracy: 0.7446\n",
      "Epoch 137/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5227 - accuracy: 0.7448\n",
      "Epoch 138/250\n",
      "804/804 [==============================] - 0s 306us/step - loss: 0.5225 - accuracy: 0.7442\n",
      "Epoch 139/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5219 - accuracy: 0.7460\n",
      "Epoch 140/250\n",
      "804/804 [==============================] - 0s 333us/step - loss: 0.5228 - accuracy: 0.7453\n",
      "Epoch 141/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5215 - accuracy: 0.7458\n",
      "Epoch 142/250\n",
      "804/804 [==============================] - 0s 307us/step - loss: 0.5222 - accuracy: 0.7453\n",
      "Epoch 143/250\n",
      "804/804 [==============================] - 0s 291us/step - loss: 0.5224 - accuracy: 0.7456\n",
      "Epoch 144/250\n",
      "804/804 [==============================] - 0s 296us/step - loss: 0.5223 - accuracy: 0.7451\n",
      "Epoch 145/250\n",
      "804/804 [==============================] - 0s 296us/step - loss: 0.5217 - accuracy: 0.7460\n",
      "Epoch 146/250\n",
      "804/804 [==============================] - 0s 302us/step - loss: 0.5225 - accuracy: 0.7453\n",
      "Epoch 147/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5218 - accuracy: 0.7458\n",
      "Epoch 148/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5218 - accuracy: 0.7456\n",
      "Epoch 149/250\n",
      "804/804 [==============================] - 0s 302us/step - loss: 0.5222 - accuracy: 0.7453\n",
      "Epoch 150/250\n",
      "804/804 [==============================] - 0s 304us/step - loss: 0.5219 - accuracy: 0.7453\n",
      "Epoch 151/250\n",
      "804/804 [==============================] - 0s 315us/step - loss: 0.5221 - accuracy: 0.7451\n",
      "Epoch 152/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5218 - accuracy: 0.7454\n",
      "Epoch 153/250\n",
      "804/804 [==============================] - 0s 292us/step - loss: 0.5218 - accuracy: 0.7458\n",
      "Epoch 154/250\n",
      "804/804 [==============================] - 0s 285us/step - loss: 0.5222 - accuracy: 0.7454\n",
      "Epoch 155/250\n",
      "804/804 [==============================] - 0s 303us/step - loss: 0.5219 - accuracy: 0.7447\n",
      "Epoch 156/250\n",
      "804/804 [==============================] - 0s 305us/step - loss: 0.5215 - accuracy: 0.7454\n",
      "Epoch 157/250\n",
      "804/804 [==============================] - 0s 305us/step - loss: 0.5217 - accuracy: 0.7455\n",
      "Epoch 158/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5214 - accuracy: 0.7460\n",
      "Epoch 159/250\n",
      "804/804 [==============================] - 0s 313us/step - loss: 0.5219 - accuracy: 0.7457\n",
      "Epoch 160/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5214 - accuracy: 0.7458\n",
      "Epoch 161/250\n",
      "804/804 [==============================] - 0s 293us/step - loss: 0.5214 - accuracy: 0.7459\n",
      "Epoch 162/250\n",
      "804/804 [==============================] - 0s 309us/step - loss: 0.5217 - accuracy: 0.7460\n",
      "Epoch 163/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5216 - accuracy: 0.7450\n",
      "Epoch 164/250\n",
      "804/804 [==============================] - 0s 300us/step - loss: 0.5217 - accuracy: 0.7459\n",
      "Epoch 165/250\n",
      "804/804 [==============================] - 0s 290us/step - loss: 0.5218 - accuracy: 0.7458\n",
      "Epoch 166/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5210 - accuracy: 0.7460\n",
      "Epoch 167/250\n",
      "804/804 [==============================] - 0s 300us/step - loss: 0.5221 - accuracy: 0.7453\n",
      "Epoch 168/250\n",
      "804/804 [==============================] - 0s 285us/step - loss: 0.5213 - accuracy: 0.7455\n",
      "Epoch 169/250\n",
      "804/804 [==============================] - 0s 284us/step - loss: 0.5222 - accuracy: 0.7449\n",
      "Epoch 170/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5210 - accuracy: 0.7465\n",
      "Epoch 171/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5211 - accuracy: 0.7454\n",
      "Epoch 172/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5212 - accuracy: 0.7459\n",
      "Epoch 173/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5220 - accuracy: 0.7462\n",
      "Epoch 174/250\n",
      "804/804 [==============================] - 0s 321us/step - loss: 0.5211 - accuracy: 0.7451\n",
      "Epoch 175/250\n",
      "804/804 [==============================] - 0s 300us/step - loss: 0.5213 - accuracy: 0.7454\n",
      "Epoch 176/250\n",
      "804/804 [==============================] - 0s 308us/step - loss: 0.5213 - accuracy: 0.7451\n",
      "Epoch 177/250\n",
      "804/804 [==============================] - 0s 297us/step - loss: 0.5211 - accuracy: 0.7457\n",
      "Epoch 178/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5212 - accuracy: 0.7459\n",
      "Epoch 179/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5210 - accuracy: 0.7455\n",
      "Epoch 180/250\n",
      "804/804 [==============================] - 0s 302us/step - loss: 0.5212 - accuracy: 0.7460\n",
      "Epoch 181/250\n",
      "804/804 [==============================] - 0s 297us/step - loss: 0.5209 - accuracy: 0.7463\n",
      "Epoch 182/250\n",
      "804/804 [==============================] - 0s 297us/step - loss: 0.5215 - accuracy: 0.7453\n",
      "Epoch 183/250\n",
      "804/804 [==============================] - 0s 317us/step - loss: 0.5213 - accuracy: 0.7465\n",
      "Epoch 184/250\n",
      "804/804 [==============================] - 0s 296us/step - loss: 0.5206 - accuracy: 0.7462\n",
      "Epoch 185/250\n",
      "804/804 [==============================] - 0s 358us/step - loss: 0.5211 - accuracy: 0.7457\n",
      "Epoch 186/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5210 - accuracy: 0.7465\n",
      "Epoch 187/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5211 - accuracy: 0.7455\n",
      "Epoch 188/250\n",
      "804/804 [==============================] - 0s 295us/step - loss: 0.5206 - accuracy: 0.7464\n",
      "Epoch 189/250\n",
      "804/804 [==============================] - 0s 300us/step - loss: 0.5208 - accuracy: 0.7462\n",
      "Epoch 190/250\n",
      "804/804 [==============================] - 0s 302us/step - loss: 0.5210 - accuracy: 0.7456\n",
      "Epoch 191/250\n",
      "804/804 [==============================] - 0s 290us/step - loss: 0.5205 - accuracy: 0.7460\n",
      "Epoch 192/250\n",
      "804/804 [==============================] - 0s 303us/step - loss: 0.5206 - accuracy: 0.7467\n",
      "Epoch 193/250\n",
      "804/804 [==============================] - 0s 311us/step - loss: 0.5209 - accuracy: 0.7459\n",
      "Epoch 194/250\n",
      "804/804 [==============================] - 0s 305us/step - loss: 0.5200 - accuracy: 0.7463\n",
      "Epoch 195/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5206 - accuracy: 0.7454\n",
      "Epoch 196/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5205 - accuracy: 0.7463\n",
      "Epoch 197/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5209 - accuracy: 0.7463\n",
      "Epoch 198/250\n",
      "804/804 [==============================] - 0s 288us/step - loss: 0.5206 - accuracy: 0.7464\n",
      "Epoch 199/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5208 - accuracy: 0.7461\n",
      "Epoch 200/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5205 - accuracy: 0.7460\n",
      "Epoch 201/250\n",
      "804/804 [==============================] - 0s 293us/step - loss: 0.5203 - accuracy: 0.7461\n",
      "Epoch 202/250\n",
      "804/804 [==============================] - 0s 299us/step - loss: 0.5205 - accuracy: 0.7458\n",
      "Epoch 203/250\n",
      "804/804 [==============================] - 0s 293us/step - loss: 0.5204 - accuracy: 0.7465\n",
      "Epoch 204/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5205 - accuracy: 0.7465\n",
      "Epoch 205/250\n",
      "804/804 [==============================] - 0s 299us/step - loss: 0.5207 - accuracy: 0.7462\n",
      "Epoch 206/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5201 - accuracy: 0.7455\n",
      "Epoch 207/250\n",
      "804/804 [==============================] - 0s 303us/step - loss: 0.5205 - accuracy: 0.7462\n",
      "Epoch 208/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5207 - accuracy: 0.7466\n",
      "Epoch 209/250\n",
      "804/804 [==============================] - 0s 293us/step - loss: 0.5205 - accuracy: 0.7462\n",
      "Epoch 210/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5202 - accuracy: 0.7460\n",
      "Epoch 211/250\n",
      "804/804 [==============================] - 0s 297us/step - loss: 0.5202 - accuracy: 0.7455\n",
      "Epoch 212/250\n",
      "804/804 [==============================] - 0s 324us/step - loss: 0.5203 - accuracy: 0.7466\n",
      "Epoch 213/250\n",
      "804/804 [==============================] - 0s 300us/step - loss: 0.5199 - accuracy: 0.7467\n",
      "Epoch 214/250\n",
      "804/804 [==============================] - 0s 302us/step - loss: 0.5205 - accuracy: 0.7464\n",
      "Epoch 215/250\n",
      "804/804 [==============================] - 0s 303us/step - loss: 0.5201 - accuracy: 0.7462\n",
      "Epoch 216/250\n",
      "804/804 [==============================] - 0s 307us/step - loss: 0.5199 - accuracy: 0.7467\n",
      "Epoch 217/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5204 - accuracy: 0.7464\n",
      "Epoch 218/250\n",
      "804/804 [==============================] - 0s 292us/step - loss: 0.5201 - accuracy: 0.7462\n",
      "Epoch 219/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5200 - accuracy: 0.7456\n",
      "Epoch 220/250\n",
      "804/804 [==============================] - 0s 386us/step - loss: 0.5196 - accuracy: 0.7460\n",
      "Epoch 221/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5198 - accuracy: 0.7464\n",
      "Epoch 222/250\n",
      "804/804 [==============================] - 0s 311us/step - loss: 0.5199 - accuracy: 0.7456\n",
      "Epoch 223/250\n",
      "804/804 [==============================] - 0s 370us/step - loss: 0.5198 - accuracy: 0.7460\n",
      "Epoch 224/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5196 - accuracy: 0.7462\n",
      "Epoch 225/250\n",
      "804/804 [==============================] - 0s 321us/step - loss: 0.5197 - accuracy: 0.7458\n",
      "Epoch 226/250\n",
      "804/804 [==============================] - 0s 339us/step - loss: 0.5197 - accuracy: 0.7457\n",
      "Epoch 227/250\n",
      "804/804 [==============================] - 0s 306us/step - loss: 0.5200 - accuracy: 0.7457\n",
      "Epoch 228/250\n",
      "804/804 [==============================] - 0s 310us/step - loss: 0.5198 - accuracy: 0.7466\n",
      "Epoch 229/250\n",
      "804/804 [==============================] - 0s 307us/step - loss: 0.5198 - accuracy: 0.7461\n",
      "Epoch 230/250\n",
      "804/804 [==============================] - 0s 302us/step - loss: 0.5198 - accuracy: 0.7459\n",
      "Epoch 231/250\n",
      "804/804 [==============================] - 0s 302us/step - loss: 0.5197 - accuracy: 0.7460\n",
      "Epoch 232/250\n",
      "804/804 [==============================] - 0s 300us/step - loss: 0.5196 - accuracy: 0.7470\n",
      "Epoch 233/250\n",
      "804/804 [==============================] - 0s 297us/step - loss: 0.5190 - accuracy: 0.7458\n",
      "Epoch 234/250\n",
      "804/804 [==============================] - 0s 282us/step - loss: 0.5198 - accuracy: 0.7460\n",
      "Epoch 235/250\n",
      "804/804 [==============================] - 0s 296us/step - loss: 0.5198 - accuracy: 0.7462\n",
      "Epoch 236/250\n",
      "804/804 [==============================] - 0s 304us/step - loss: 0.5192 - accuracy: 0.7460\n",
      "Epoch 237/250\n",
      "804/804 [==============================] - 0s 306us/step - loss: 0.5194 - accuracy: 0.7464\n",
      "Epoch 238/250\n",
      "804/804 [==============================] - 0s 304us/step - loss: 0.5196 - accuracy: 0.7459\n",
      "Epoch 239/250\n",
      "804/804 [==============================] - 0s 305us/step - loss: 0.5189 - accuracy: 0.7467\n",
      "Epoch 240/250\n",
      "804/804 [==============================] - 0s 297us/step - loss: 0.5199 - accuracy: 0.7458\n",
      "Epoch 241/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5206 - accuracy: 0.7465\n",
      "Epoch 242/250\n",
      "804/804 [==============================] - 0s 326us/step - loss: 0.5195 - accuracy: 0.7472\n",
      "Epoch 243/250\n",
      "804/804 [==============================] - 0s 294us/step - loss: 0.5196 - accuracy: 0.7457\n",
      "Epoch 244/250\n",
      "804/804 [==============================] - 0s 292us/step - loss: 0.5192 - accuracy: 0.7462\n",
      "Epoch 245/250\n",
      "804/804 [==============================] - 0s 318us/step - loss: 0.5193 - accuracy: 0.7466\n",
      "Epoch 246/250\n",
      "804/804 [==============================] - 0s 311us/step - loss: 0.5194 - accuracy: 0.7461\n",
      "Epoch 247/250\n",
      "804/804 [==============================] - 0s 301us/step - loss: 0.5195 - accuracy: 0.7465\n",
      "Epoch 248/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5195 - accuracy: 0.7468\n",
      "Epoch 249/250\n",
      "804/804 [==============================] - 0s 298us/step - loss: 0.5194 - accuracy: 0.7470\n",
      "Epoch 250/250\n",
      "804/804 [==============================] - 0s 300us/step - loss: 0.5191 - accuracy: 0.7466\n"
     ]
    }
   ],
   "source": [
    "fit_nn6 = nn6.fit(X_train_scaled, y_train, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5640 - accuracy: 0.7296 - 239ms/epoch - 892us/step\n",
      "Loss: 0.5640283226966858, Accuracy: 0.7295626997947693\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn6.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14033826c08>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df6 = pd.DataFrame(fit_nn6.history)\n",
    "\n",
    "# Increase the index by 1 to match the number of epochs\n",
    "history_df6.index += 1\n",
    "\n",
    "# Plot the loss\n",
    "history_df6.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('PythonData')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1487494d1930e91d962159de15fe4593b68bb1e7b34efac8b35e8bd9484bfe5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
